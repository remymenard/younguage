---
- :url: https://medium.com/thrive-global/how-technology-hijacks-peoples-minds-from-a-magician-and-google-s-design-ethicist-56d62ef5edf3?source=search_post---------0
  :title: How Technology is Hijacking Your Mind — from a Former Insider
  :content: '<p>Estimated reading time: 15 minutes.</p><blockquote><p>“It’s easier
    to fool people than to convince them that they’ve been fooled.” — Unknown.</p></blockquote><p>I’m
    an expert on how technology hijacks our psychological vulnerabilities. That’s
    why I spent the last three years as a Design Ethicist at Google caring about how
    to design things in a way that defends a billion people’s minds from getting hijacked.</p><p>When
    using technology, we often focus <em>optimistically</em> on all the things it
    does for us. But I want to show you where it might do the opposite.</p><p><em>Where
    does technology exploit our minds’ weaknesses</em>?</p><p>I learned to think this
    way when I was a magician. Magicians start by looking for <em>blind spots, edges,
    vulnerabilities and</em> <em>limits</em> of people’s perception, so they can influence
    what people do without them even realizing it. Once you know how to push people’s
    buttons, you can play them like a piano.</p><p><img src="https://cdn-images-1.medium.com/max/2892/1*IG2MfhS05JjHryBHnXLXwA.png"
    alt="That’s me performing sleight of hand magic at my mother’s birthday party"><em>That’s
    me performing sleight of hand magic at my mother’s birthday party</em></p><p>And
    this is exactly what product designers do to your mind. They play your psychological
    vulnerabilities (consciously and unconsciously) against you in the race to grab
    your attention.</p><p>I want to show you how they do it.</p><h3>Hijack #1: If
    You Control the Menu, You Control the Choices</h3><p><img src="https://cdn-images-1.medium.com/max/2000/1*kW01thCZaWQyq0A08hSj5Q.png"
    alt=""></p><p>Western Culture is built around ideals of individual choice and
    freedom. Millions of us fiercely defend our right to make “free” choices, while
    we ignore how those choices are manipulated upstream by menus we didn’t choose
    in the first place.</p><p>This is exactly what magicians do. They give people
    the illusion of free choice while architecting the menu so that they win, no matter
    what you choose. I can’t emphasize enough how deep this insight is.</p><p>When
    people are given a menu of choices, they rarely ask:</p><ul><li><p>“what’s not
    on the menu?”</p></li><li><p>“why am I being given <em>these options</em> and
    not others?”</p></li><li><p>“do I know the menu provider’s goals?”</p></li><li><p>“is
    this menu <em>empowering</em> for my original need, or are the choices actually
    a distraction?” (e.g. an overwhelmingly array of toothpastes)</p></li></ul><p><img
    src="https://cdn-images-1.medium.com/max/2000/1*-h0aCLf8EH5OxCIdMXERgA.jpeg" alt="How
    *empowering is this menu* of choices for the need, “I ran out of toothpaste”?"><em>How
    *empowering is this menu</em> of choices for the need, “I ran out of toothpaste”?*</p><p>For
    example, imagine you’re out with friends on a Tuesday night and want to keep the
    conversation going. You open Yelp to find nearby recommendations and see a list
    of bars. The group turns into a huddle of faces staring down at their phones *comparing
    bars. *They scrutinize the photos of each, comparing cocktail drinks. Is this
    menu still relevant to the original desire of the group?</p><p>It’s not that bars
    aren’t a good choice, it’s that Yelp substituted the group’s original question
    (“where can we go to keep talking?”) with a different question (“what’s a bar
    with good photos of cocktails?”) all by shaping the menu.</p><p>Moreover, the
    group falls for the illusion that Yelp’s menu represents a <em>complete set of
    choices</em> for where to go. While looking down at their phones, they don’t see
    the park across the street with a band playing live music. They miss the pop-up
    gallery on the other side of the street serving crepes and coffee. Neither of
    those show up on Yelp’s menu.</p><p><img src="https://cdn-images-1.medium.com/max/2218/1*Ih_bIVQ12Ibu076252-bKA.png"
    alt="Yelp subtly reframes the group’s need “where can we go to keep talking?”
    in terms of photos of cocktails served."><em>Yelp subtly reframes the group’s
    need “where can we go to keep talking?” in terms of photos of cocktails served.</em></p><p>The
    more choices technology gives us in nearly every domain of our lives (information,
    events, places to go, friends, dating, jobs) — <em>the more we assume that our
    phone is always the most empowering and useful menu to pick from</em>. Is it?</p><p><em>**The
    “most empowering” menu is different than the menu that has the most choices</em>*.
    *But when we blindly surrender to the menus we’re given, it’s easy to lose track
    of the difference:</p><ul><li><p>“Who’s free tonight to hang out?” becomes a menu
    of *most recent people who texted us *(who we could ping).</p></li><li><p>“What’s
    happening in the world?” becomes a menu of news feed stories.</p></li><li><p>“Who’s
    single to go on a date?” becomes a menu* *of faces to swipe on Tinder (instead
    of local events with friends, or urban adventures nearby).</p></li><li><p>“I have
    to respond to this email.” becomes a menu of <em>keys to type a response</em>
    (instead of empowering ways to communicate with a person).</p></li></ul><p><img
    src="https://cdn-images-1.medium.com/max/2000/1*LsgYHAM-xhnkYGSkocOmew.png" alt="All
    user interfaces are menus. What if your email client gave you *empowering choices
    of ways to respond, instead of “what message do you want to type back?” (Design
    by Tristan Harris)*"><em>All user interfaces are menus. What if your email client
    gave you *empowering choices of ways to respond, instead of “what message do you
    want to type back?” (Design by Tristan Harris)</em>*</p><p>When we wake up in
    the morning and turn our phone over to see a list of notifications — it frames
    the experience of “waking up in the morning” around a menu of “all the things
    I’ve missed since yesterday.” (for more examples, see <a href="https://vimeo.com/123488311">Joe
    Edelman’s Empowering Design talk</a>)</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*iDMEQ0vQrx2ep_Z4G-mY1w.png"
    alt="A list of notifications when we wake up in the morning — how *empowering
    is this menu of choices when we wake up? Does it reflect what we care about? (from
    [Joe Edelman’s Empowering Design Talk](https://vimeo.com/123488311))*"><em>A list
    of notifications when we wake up in the morning — how *empowering is this menu
    of choices when we wake up? Does it reflect what we care about? (from <a href="https://vimeo.com/123488311">Joe
    Edelman’s Empowering Design Talk</a>)</em>*</p><p>By shaping the menus we pick
    from, technology hijacks the way we perceive our choices and replaces them with
    new ones. But the closer we pay attention to the options we’re given, the more
    we’ll notice when they don’t actually align with our true needs.</p><h3><strong>Hijack
    #2: Put a Slot Machine In a Billion Pockets</strong></h3><p>If you’re an app,
    how do you keep people hooked? Turn yourself into a slot machine.</p><p>The average
    person checks their phone 150 times a day. Why do we do this? Are we making <em>150</em>
    <em>conscious</em> <em>choices</em>?</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*BNOfmUQ2nTRVPVe0CHx7ew.png"
    alt="How often do you check your email per day?"><em>How often do you check your
    email per day?</em></p><p>One major reason why is the #1 psychological ingredient
    in slot machines: <a href="https://en.wikipedia.org/wiki/Reinforcement#Intermittent_reinforcement.3B_schedules">**intermittent
    variable rewards</a>**.</p><p>If you want to maximize addictiveness, all tech
    designers need to do is link a user’s action (like pulling a lever) with a <em>variable
    reward</em>. You pull a lever and immediately receive either an enticing reward
    (a match, a prize!) or nothing. Addictiveness is maximized when the rate of reward
    is most variable.</p><p>Does this effect really work on people? Yes. <strong>Slot
    machines make more money in the United States than baseball, movies, and theme
    parks <a href="http://www.cbsnews.com/news/slot-machines-the-big-gamble-07-01-2011/">combined</a>*.</strong>*
    Relative to other kinds of gambling, people get ‘problematically involved’ with
    slot machines <a href="http://99percentinvisible.org/episode/episode-78-no-armed-bandit/">**3–4x
    faster</a>*** <em>according to NYU professor Natasha Dow Schull, author of *Addiction
    by Design.</em></p><p><img src="https://cdn-images-1.medium.com/max/5184/1*jv-w56ymDBTwsiqx7YdIdQ.jpeg"
    alt="Image courtesy of Jopwell"><em>Image courtesy of Jopwell</em></p><p><strong>But
    here’s the unfortunate truth — several billion people have a slot machine their
    pocket:</strong></p><ul><li><p>When we pull our phone out of our pocket, we’re
    <em>playing a slot machine</em> to see what notifications we got.</p></li><li><p>When
    we pull to refresh our email, we’re *playing a slot machine *to see what new email
    we got.</p></li><li><p>When we swipe down our finger to scroll the Instagram feed,
    we’re <em>playing a slot machine</em> to see what photo comes next.</p></li><li><p>When
    we swipe faces left/right on dating apps like Tinder, we’re <em>playing a slot
    machine</em> to see if we got a match.</p></li><li><p>When we tap the # of red
    notifications, we’re *playing a slot machine *to what’s underneath.</p></li></ul><p><img
    src="https://cdn-images-1.medium.com/max/2000/1*IoBUUcjfeAUnmY2ccu75Ww.png" alt=""></p><p>Apps
    and websites sprinkle intermittent variable rewards all over their products because
    it’s good for business.</p><p>But in other cases, slot machines emerge by accident.
    For example, there is no malicious corporation behind <em>all of email</em> who
    consciously chose to make it a slot machine. No one profits when millions check
    their email and nothing’s there. Neither did Apple and Google’s designers <em>want</em>
    phones to work like slot machines. It emerged by accident.</p><p>But now companies
    like Apple and Google have a responsibility to reduce these effects by <em>converting
    intermittent variable rewards into less addictive, more predictable ones</em>
    with better design. For example, they could empower people to set predictable
    times during the day or week for when they want to check “slot machine” apps,
    and correspondingly adjust when new messages are delivered to align with those
    times.</p><h3>Hijack #3: Fear of Missing Something Important (FOMSI)</h3><p>Another
    way apps and websites hijack people’s minds is by inducing a “1% chance you could
    be missing something important.”</p><p>If I convince you that I’m a channel for
    important information, messages, friendships, or potential sexual opportunities
    — it will be hard for you to turn me off, unsubscribe, or remove your account
    — because (aha, I win) you might miss something important:</p><ul><li><p>This
    keeps us subscribed to newsletters even after they haven’t delivered recent benefits
    (“what if I miss a future announcement?”)</p></li><li><p>This keeps us “friended”
    to people with whom we haven’t spoke in ages (“what if I miss something important
    from them?”)</p></li><li><p>This keeps us swiping faces on dating apps, even when
    we haven’t even met up with anyone in a while (“what if I miss that <em>one hot
    match</em> who likes me?”)</p></li><li><p>This keeps us using social media (“what
    if I miss that important news story or fall behind what my friends are talking
    about?”)</p></li></ul><p>But if we zoom into that fear, we’ll discover that it’s
    unbounded*: we’ll always miss something important *at any point when we stop using
    something.</p><ul><li><p>There are magic moments on Facebook we’ll miss by not
    using it for the 6th hour (e.g. an old friend who’s visiting town <em>right now</em>).</p></li><li><p>There
    are magic moments we’ll miss on Tinder (e.g. our dream romantic partner) by not
    swiping our 700th match.</p></li><li><p>There are emergency phone calls we’ll
    miss if we’re not connected 24/7<em>.</em></p></li></ul><p><em>But living moment
    to moment with the fear of missing something isn’t how we’re built to live.</em></p><p>And
    it’s amazing how quickly, once we let go of that fear, we wake up from the illusion.
    When we unplug for more than a day, unsubscribe from those notifications, or go
    to <a href="http://campgrounded.org">Camp Grounded</a> — the concerns we thought
    we’d have don’t actually happen.</p><p><em>We don’t miss what we don’t see.</em></p><p>The
    thought, “what if I miss something important?” is generated *in advance of unplugging,
    unsubscribing, or turning off *— not after. Imagine if tech companies recognized
    that, and helped us proactively tune our relationships with friends and businesses
    in terms of what we define as “<a href="http://timewellspent.io">time well spent</a>”
    for our lives, instead of in terms of what we might miss.</p><h3>Hijack #4: Social
    Approval</h3><p><img src="https://cdn-images-1.medium.com/max/2000/1*qnyJGSiHouwhM_rhhvy_rA.png"
    alt="Easily one of the most persuasive things a human being can receive."><em>Easily
    one of the most persuasive things a human being can receive.</em></p><p>We’re
    all vulnerable to <strong>social approval</strong>. The need to belong, to be
    approved or appreciated by our peers is among the highest human motivations. But
    now our social approval is in the hands of tech companies.</p><p>When I get tagged
    by my friend Marc, I imagine him making a *conscious choice *to tag me. But I
    don’t see how a company like Facebook orchestrated his doing that in the first
    place.</p><p>Facebook, Instagram or SnapChat can manipulate how often people get
    tagged in photos by automatically suggesting all the faces people should tag (e.g.
    by showing a box with a 1-click confirmation, “Tag Tristan in this photo?”).</p><p>So
    when Marc tags me, <em>he’s actually</em> <em>responding to Facebook’s suggestion,</em>
    not making an independent choice. But through design choices like this, <em>Facebook
    controls the multiplier for</em> <em>how often millions of people experience their
    social approval on the line</em>.</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*YkxjEeZ_CO0a2Gp9Awf_bQ.png"
    alt="Facebook uses automatic suggestions like this to get people to tag more people,
    creating more social externalities and interruptions."><em>Facebook uses automatic
    suggestions like this to get people to tag more people, creating more social externalities
    and interruptions.</em></p><p>The same happens when we change our main profile
    photo — Facebook knows that’s a moment when we’re <em>vulnerable to social approval</em>:
    *“what do my friends think of my new pic?” *Facebook can rank this higher in the
    news feed, so it sticks around for longer and more friends will like or comment
    on it. Each time they like or comment on it, we’ll get pulled right back.</p><p>Everyone
    innately responds to social approval, but some demographics (teenagers) are more
    vulnerable to it than others. That’s why it’s so important to recognize how powerful
    designers are when they exploit this vulnerability.</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*7Gt5k-6sigW8e1QoLARuYg.png"
    alt=""></p><h3>Hijack #5: Social Reciprocity (Tit-for-tat)</h3><ul><li><p>You
    do me a favor — I owe you one next time.</p></li><li><p>You say, “thank you”—
    I have to say “you’re welcome.”</p></li><li><p>You send me an email— it’s rude
    not to get back to you.</p></li><li><p>You follow me — it’s rude not to follow
    you back. (especially for teenagers)</p></li></ul><p>We are <em>vulnerable</em>
    <em>to needing to reciprocate others’ gestures</em>. But as with Social Approval,
    tech companies now manipulate how often we experience it.</p><p>In some cases,
    it’s by accident.* Email, texting and messaging apps are social reciprocity factories*.
    But in other cases, companies exploit this vulnerability on purpose.</p><p>LinkedIn
    is the most obvious offender. LinkedIn wants as many people creating social obligations
    for each other as possible, because each time they reciprocate (by accepting a
    connection, responding to a message, or endorsing someone back for a skill) they
    have to come back to linkedin.com where they can get people to spend more time.</p><p>Like
    Facebook, LinkedIn exploits an asymmetry in perception. When you receive an invitation
    from someone to connect, you imagine that person making a <em>conscious choice</em>
    to invite you, when in reality, they likely unconsciously responded to LinkedIn’s
    list of suggested contacts. In other words, LinkedIn turns your* unconscious impulses*
    (to “add” a person) into new social obligations that millions of people feel obligated
    to repay. All while they profit from the time people spend doing it.</p><p><img
    src="https://cdn-images-1.medium.com/max/2000/1*B5ZVhb7eL7hyEcfS8m1onQ.png" alt=""></p><p>Imagine
    millions of people getting interrupted like this throughout their day, running
    around like chickens with their heads cut off, reciprocating each other — all
    designed by companies who profit from it.</p><p>Welcome to social media.</p><p><img
    src="https://cdn-images-1.medium.com/max/2000/1*GcrioynC_fnLRB4Vmu-X_g.png" alt="After
    accepting an endorsement, LinkedIn takes advantage of your bias to reciprocate
    by offering *four* additional people for you to endorse in return."><em>After
    accepting an endorsement, LinkedIn takes advantage of your bias to reciprocate
    by offering *four</em> additional people for you to endorse in return.*</p><p>Imagine
    if technology companies had a responsibility to minimize social reciprocity. Or
    if there was an independent organization that represented the public’s interests
    — an industry consortium or an FDA for tech — that monitored when technology companies
    abused these biases?</p><p><img src="https://cdn-images-1.medium.com/max/2068/1*5wyghDrGzpUYxGZkZRzE_A.png"
    alt=""></p><h3><strong>Hijack #6: Bottomless bowls, Infinite Feeds, and Autoplay</strong></h3><p><img
    src="https://cdn-images-1.medium.com/max/2000/1*d_4O5k_1k9LLadu3HMmtXg.png" alt="YouTube
    autoplays the next video after a countdown"><em>YouTube autoplays the next video
    after a countdown</em></p><p>Another way to hijack people is to keep them consuming
    things, even when they aren’t hungry anymore.</p><p>How? Easy. <em>Take an experience
    that was bounded and finite, and turn it into a bottomless flow</em> <em>that
    keeps going</em>.</p><p>Cornell professor Brian Wansink demonstrated this in his
    study showing <a href="http://foodpsychology.cornell.edu/discoveries/bottomless-bowls">you
    can trick people into keep eating soup by giving them a bottomless bowl</a> that
    automatically refills as they eat. With bottomless bowls, people eat 73% more
    calories than those with normal bowls and underestimate how many calories they
    ate by 140 calories.</p><p>Tech companies exploit the same principle. News feeds
    are purposely designed to auto-refill with reasons to keep you scrolling, and
    purposely eliminate any reason for you to pause, reconsider or leave.</p><p>It’s
    also why video and social media sites like Netflix, YouTube or Facebook <em>autoplay</em>
    the next video after a countdown instead of waiting for you to make a conscious
    choice (in case you won’t). A huge portion of traffic on these websites is driven
    by autoplaying the next thing.</p><p><img src="https://cdn-images-1.medium.com/max/3064/1*y2lmMCXN6papGONxwGDazA.png"
    alt=""></p><p><img src="https://cdn-images-1.medium.com/max/2000/1*l1rcapgZdtApL4rph3Sj3A.jpeg"
    alt="Facebook autoplays the next video after a countdown"><em>Facebook autoplays
    the next video after a countdown</em></p><p>Tech companies often claim that “we’re
    just making it easier for users to see the video <em>they want</em> to watch”
    when they are actually serving their business interests. And you can’t blame them,
    because increasing “time spent” is the currency they compete for.</p><p>Instead,
    imagine if technology companies empowered you to <em>consciously bound your experience
    *to align with what would be “<a href="http://timewellspent.io">time well spent</a>”
    for you. Not just bounding the *quantity *of time you spend, but the *qualities</em>
    of what would be “time well spent.”</p><h3>Hijack #7: Instant Interruption vs.
    “Respectful” Delivery</h3><p>Companies know that messages *that interrupt people
    immediately are more persuasive at getting people to respond *than messages delivered
    asynchronously (like email or any deferred inbox).</p><p>Given the choice, Facebook
    Messenger (or WhatsApp, WeChat or SnapChat for that matter) would <em>prefer to
    design their messaging system to</em> *interrupt recipients immediately (and show
    a chat box) *instead of helping users respect each other’s attention.</p><p>In
    other words, <strong>interruption is good for business</strong>.</p><p>It’s also
    in their interest to heighten the feeling of urgency and social reciprocity. For
    example, Facebook automatically <em>tells the sender when you “saw” their message,
    instead of letting you avoid disclosing whether you read it</em> (“now that you
    know I’ve seen the message, I feel even more obligated to respond.”)</p><p>By
    contrast, Apple more respectfully lets users toggle “Read Receipts” on or off.</p><p>The
    problem is, maximizing interruptions in the name of business creates a tragedy
    of the commons, ruining global attention spans and causing billions of unnecessary
    interruptions each day. This is a huge problem we need to fix with shared design
    standards (potentially, as part of <a href="http://timewellspent.io">Time Well
    Spent</a>).</p><h3>Hijack #8: Bundling Your Reasons with Their Reasons</h3><p>Another
    way apps hijack you is by taking <em>your reasons</em> for visiting the app (to
    perform a task) and <em>make them inseparable from the app’s business reasons</em>
    (maximizing how much we consume once we’re there).</p><p>For example, in the physical
    world of grocery stores, the #1 and #2 most popular reasons to visit are pharmacy
    refills and buying milk. But grocery stores want to maximize how much people buy,
    so they put the pharmacy and the milk at the back of the store.</p><p><em>In other
    words, they make the thing customers want (milk, pharmacy) inseparable from what
    the business wants.</em> If stores were <em>truly organized to support people</em>,
    they would <a href="http://www.economist.com/node/12792420">put the most popular
    items in the front</a>.</p><p>Tech companies design their websites the same way.
    For example, when you you want to look up a Facebook event happening tonight (your
    reason) the Facebook app doesn’t allow you to access it without first landing
    on the news feed (their reasons), and that’s on purpose. <em>Facebook wants to
    convert every reason you have for using Facebook, into their reason which is to
    maximize the time you spend consuming things</em>.</p><p>Instead, imagine if …</p><ul><li><p>Twitter
    gave you a <em>separate way</em> to post a tweet than having to see their news
    feed.</p></li><li><p>Facebook gave a <em>separate way</em> to look up Facebook
    Events going on tonight, without being forced to use their news feed.</p></li><li><p>Facebook
    gave you a <em>separate way</em> to use Facebook Connect as a passport for creating
    new accounts on 3rd party apps and websites, without being forced to install Facebook’s
    entire app, news feed and notifications.</p></li></ul><p>In a <a href="http://timewellspent.io">Time
    Well Spent world</a>, there is always a <em>direct way</em> to get what you want
    <em>separately</em> from what businesses want. Imagine a digital “bill of rights”
    outlining design standards that forced the products used by billions of people
    to let them navigate directly to what they want without needing to go through
    intentionally placed distractions.</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*HkSOLmgs_RAiKbRMJt9HxA.png"
    alt="Imagine if web browsers empowered you to navigate directly to what you want
    — especially for sites that intentionally detour you toward their reasons."><em>Imagine
    if web browsers empowered you to navigate directly to what you want — especially
    for sites that intentionally detour you toward their reasons.</em></p><h3><strong>Hijack
    #9: Inconvenient Choices</strong></h3><p>We’re told that it’s enough for businesses
    to “make choices available.”</p><ul><li><p>“If you don’t like it you can always
    use a different product.”</p></li><li><p>“If you don’t like it, you can always
    unsubscribe.”</p></li><li><p>“If you’re addicted to our app, you can always uninstall
    it from your phone.”</p></li></ul><p>Businesses naturally <em>want to make the
    choices they want you to make easier, and the choices they don’t want you to make
    harder.</em> Magicians do the same thing. You make it easier for a spectator to
    pick the thing you want them to pick, and harder to pick the thing you don’t.</p><p>For
    example, NYTimes.com lets you “make a free choice” to cancel your digital subscription.
    But instead of just doing it when you hit “Cancel Subscription,” they <em>send
    you an email with information on how to cancel your account by calling a phone
    number</em> that’s only open at certain times.</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*kSGi-JcMMGgwigs6VgFY2A.png"
    alt="NYTimes claims it’s giving a free choice to cancel your account"><em>NYTimes
    claims it’s giving a free choice to cancel your account</em></p><p>Instead of
    viewing the world in terms of <em>availability of choices</em>, we should view
    the world in terms of <em>friction required to enact choices</em>. Imagine a world
    where choices were labeled with how difficult they were to fulfill (like coefficients
    of friction) and there was an independent entity — an industry consortium or non-profit
    — that labeled these difficulties and set standards for how easy navigation should
    be.</p><h3>Hijack #10: Forecasting Errors, “Foot in the Door” strategies</h3><p><img
    src="https://cdn-images-1.medium.com/max/2000/1*vQ7yG7niPETreL7zjBuFkA.png" alt="Facebook
    promises an easy choice to “See Photo.” Would we still click if it gave the true
    price tag?"><em>Facebook promises an easy choice to “See Photo.” Would we still
    click if it gave the true price tag?</em></p><p>Lastly, apps can exploit people’s
    inability to forecast the consequences of a click.</p><p>People don’t intuitively
    forecast the <em>true cost</em> *of a click *when it’s presented to them. Sales
    people use “foot in the door” techniques by asking for a small innocuous request
    to begin with (“just one click to see which tweet got retweeted”) and escalate
    from there (“why don’t you stay awhile?”). Virtually all engagement websites use
    this trick.</p><p>Imagine if web browsers and smartphones, the gateways through
    which people make these choices, were truly watching out for people and helped
    them forecast the consequences of clicks (based on real data about <a href="https://github.com/jxe/hindsight">what
    benefits and costs it actually had</a>?).</p><p>That’s why I add “Estimated reading
    time” to the top of my posts. When you put the “true cost” of a choice in front
    of people, you’re treating your users or audience with dignity and respect. In
    a <a href="http://timewellspent.io">Time Well Spent</a> internet, choices could
    be framed in terms of projected cost and benefit, so people were empowered to
    make informed choices by default, not by doing extra work.</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*Xvo46OL3h2wDdb7S7AA1uQ.png"
    alt="TripAdvisor uses a “foot in the door” technique by asking for a single click
    review (“How many stars?”) while hiding the three page survey of questions behind
    the click."><em>TripAdvisor uses a “foot in the door” technique by asking for
    a single click review (“How many stars?”) while hiding the three page survey of
    questions behind the click.</em></p><h3>Summary And How We Can Fix This</h3><p>Are
    you upset that technology hijacks your agency? I am too. I’ve listed a few techniques
    but there are literally thousands. Imagine whole bookshelves, seminars, workshops
    and trainings that teach aspiring tech entrepreneurs techniques like these. Imagine
    hundreds of engineers whose job every day is to invent new ways to keep you hooked.</p><p>The
    ultimate freedom is a free mind, and we need technology that’s on our team to
    help us live, feel, think and act freely.</p><p>We need our smartphones, notifications
    screens and web browsers to be exoskeletons for our minds and interpersonal relationships
    that put our values, not our impulses, first. <a href="http://timewellspent.io">People’s
    time is valuable</a>. And we should protect it with the same rigor as privacy
    and other digital rights.</p><p><em>Tristan Harris was a Design Ethicist at Google
    until 2016 where he studied how technology restructures two billion people’s attention,
    wellbeing and behavior. For more resources on Time Well Spent and the Center for
    Humane Technology, see <a href="http://humanetech.com">http://humanetech.com</a>.</em></p><p><strong>UPDATE:
    The first version of this post lacked acknowledgements to those who inspired my
    thinking over many years including <a href="http://nxhx.org">Joe Edelman</a>,
    <a href="http://azarask.in">Aza Raskin</a>, <a href="http://www.raphdamico.com">Raph
    D’Amico</a>, <a href="http://appliedcognitivescience.com">Shaun Martin</a>, <a
    href="http://number27.org">Jonathan Harris</a> and <a href="https://www.ted.com/talks/damon_horowitz?language=en">Damon
    Horowitz</a>.</strong></p><p><strong>My thinking on menus and choicemaking are
    deeply rooted in Joe Edelman’s <a href="http://nxhx.org/Choicemaking/">work on
    Human Values and Choicemaking</a>.</strong></p>'
  :author: Thrive Global
  :topic_id: 728
- :url: https://medium.com/@kaistinchcombe/decentralized-and-trustless-crypto-paradise-is-actually-a-medieval-hellhole-c1ca122efdec?source=search_post---------1
  :title: Blockchain is not only crappy technology but a bad vision for the future
  :content: '<p>Blockchain is not only crappy technology but a bad vision for the
    future. Its failure to achieve adoption to date is because systems built on trust,
    norms, and institutions inherently function better than the type of no-need-for-trusted-parties
    systems blockchain envisions. That’s permanent: no matter how much blockchain
    improves it is still headed in the wrong direction.</p><p>This December I wrote
    a <a href="http://www.sohu.com/a/213276912_114778">w</a>i<a href="https://www.calcalist.co.il/markets/articles/0,7340,L-3728835,00.html">d</a>e<a
    href="https://www.bright.nl/bright-business/blockchain-heeft-geen-toegevoegde-waarde">l</a>y-<a
    href="http://news.joins.com/article/22236321">c</a>i<a href="https://www.e15.cz/kryptomeny/analytik-revoluce-se-nekona-blockchain-stale-ceka-na-vetsi-vyuziti-mimo-bitcoin-1341547">r</a>c<a
    href="https://chibicode.com/jp/blockchain/">u</a>l<a href="https://www.americanbanker.com/opinion/dont-believe-the-hype-there-are-no-good-uses-for-blockchain">a</a>t<a
    href="https://www.cnbc.com/2017/12/26/ten-years-in-nobody-has-come-up-with-a-use-for-blockchain.html?__source=facebook%7Cmain">e</a>d
    <a href="https://hackernoon.com/ten-years-in-nobody-has-come-up-with-a-use-case-for-blockchain-ee98c180100">article</a>
    on the inapplicability of blockchain to any actual problem. People objected mostly
    not to the technology argument, but rather <a href="https://medium.com/@DisRconsult/ok-im-only-a-cpa-with-some-legal-experience-background-74467b057b9d">hoped</a>
    <a href="https://medium.com/@matthewpirkowski/my-comment-has-little-to-do-with-the-number-of-possible-comparisons-and-everything-to-do-with-the-32b8e460e085">that</a>
    <a href="https://medium.com/@nickramos/great-points-but-you-are-missing-the-most-important-use-case-and-the-need-for-it-is-happening-666aa5de8708">decentralization</a>
    <a href="https://medium.com/@conches/the-reason-why-i-am-hopeful-for-the-blockchain-is-not-to-do-what-we-are-already-doing-better-but-to-87d80ed293b6">could</a>
    <a href="https://venturebeat.com/2017/12/23/why-you-want-blockchain-based-ai-even-if-you-dont-know-it-yet/">produce</a>
    <a href="https://medium.com/@brianhanley/the-real-meaning-of-cryptocurrency-is-the-same-one-that-drove-ben-franklin-to-print-money-for-the-7dd2aae9cd28">integrity</a>.</p><p>Let’s
    start with this: Venmo is a free service to transfer dollars, and bitcoin transfers
    are not free. Yet after I wrote<a href="https://medium.com/@kaistinchcombe/ten-years-in-nobody-has-come-up-with-a-use-case-for-blockchain-ee98c180100">
    an article last December</a> saying bitcoin had no use, someone<a href="https://medium.com/@aaronjmendelsohn/there-is-so-much-wrong-with-this-i-couldnt-get-through-it-all-2dd24a109e0c">
    responded</a> that Venmo and Paypal are raking in consumers’ money and people
    should switch to bitcoin.</p><p>What a surreal contrast between blockchain’s non-usefulness/non-adoption
    and the conviction of its believers! It’s so entirely evident that this person
    didn’t become a bitcoin enthusiast because they were looking for a convenient,
    free way to transfer money from one person to another and discovered bitcoin.
    In fact, I would assert that there is <em>no single person in existence</em> who
    had a problem they wanted to solve, discovered that an available blockchain solution
    was the best way to solve it, and therefore became a blockchain enthusiast.</p><blockquote><h1>There
    is <em>no single person in existence</em> who had a problem they wanted to solve,
    discovered that an available blockchain solution was the best way to solve it,
    and therefore became a blockchain enthusiast.</h1></blockquote><p>The number of
    retailers accepting cryptocurrency as a form of payment is<a href="http://www.businessinsider.com/bitcoin-price-rises-but-retailers-wont-accept-it-7-2017">
    declining</a>, and its biggest corporate boosters like <a href="https://www.google.com/search?q=ibm+supply+chain+solutions">IBM</a>,
    <a href="http://ir.nasdaq.com/releasedetail.cfm?releaseid=948326">NASDAQ</a>,
    <a href="https://www.coindesk.com/fidelity-ceo-talks-love-bitcoin-blockchain-will-change-markets/">Fidelity</a>,
    <a href="https://www.linkedin.com/pulse/swift-official-blockchain-dead-end-patrick-mcconnell/">Swift</a>
    and Walmart have gone long on press but short on actual rollout. Even the most
    prominent blockchain company, Ripple, <a href="https://www.bloomberg.com/news/articles/2018-01-25/ripple-wants-xrp-to-be-bitcoin-for-banks-if-only-the-banks-wanted-it">doesn’t
    use blockchain in its product</a>. You read that right: the company <em>Ripple</em>
    decided the best way to move money across international borders was to <em>not
    use Ripples</em>.</p><h3>A blockchain is a literal technology, not a metaphor</h3><p>Why
    all the enthusiasm for something so useless in practice?</p><p>People have made
    a number of implausible claims about the future of blockchain—like that you <a
    href="https://venturebeat.com/2017/12/23/why-you-want-blockchain-based-ai-even-if-you-dont-know-it-yet/">should
    use it for AI</a> in place of the type of behavior-tracking that google and facebook
    do, for example. This is based on a misunderstanding of what a blockchain is.
    A blockchain isn’t an ethereal thing out there in the universe that you can “put”
    things into, it’s a specific data structure: a linear transaction log, typically
    replicated by computers whose owners (called miners) are rewarded for logging
    new transactions.</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*O2IXj90Y2XxXdZRpwt8wkw.png"
    alt="In The Golden Compass, Dust permeates the world. It is created by consciousness
    and is itself conscious, and can condense into angels. Blockchain is not like
    that."><em>In The Golden Compass, Dust permeates the world. It is created by consciousness
    and is itself conscious, and can condense into angels. Blockchain is not like
    that.</em></p><p>There are two things that are cool about this particular data
    structure. One is that a change in any block invalidates every block after it,
    which means that you can’t tamper with historical transactions. The second is
    that you only get rewarded if you’re working on the same chain as everyone else,
    so each participant has an incentive to go with the consensus.</p><p>The end result
    is a shared definitive historical record. And, what’s more, because consensus
    is formed by each person acting in their own interest, adding a false transaction
    or working from a different history just means you’re not getting paid and everyone
    else is. Following the rules is mathematically enforced—no government or police
    force need come in and tell you the transaction you’ve logged is false (or extort
    bribes or bully the participants). It’s a powerful idea.</p><p>So in summary,
    here’s what blockchain-the-technology is: <em>“Let’s create a very long sequence
    of small files — each one containing a hash of the previous file, some new data,
    and the answer to a difficult math problem — and divide up some money every hour
    among anyone willing to certify and store those files for us on their computers.”</em></p><p>Now,
    here’s what blockchain-the-metaphor is: <em>“What if everyone keeps their records
    in a tamper-proof repository not owned by anyone?”</em></p><p>An illustration
    of the difference: In 2006, Walmart launched a system to track its bananas and
    mangoes from field to store. In 2009 they abandoned it because of logistical problems
    getting everyone to enter the data, and in 2017 they re-launched it (to <a href="https://www.google.com/search?q=%22six%20days,%2018%20hours,%20and%2026%20minutes%22">much
    fanfare</a>) on blockchain. If someone comes to you with “the mango-pickers don’t
    like doing data entry,” “I know: let’s create a very long sequence of small files,
    each one containing a hash of the previous file” is a nonsense answer, but “What
    if everyone keeps their records in a tamper-proof repository not owned by anyone?”
    at least addresses the right question!</p><h3>Blockchain-based trustworthiness
    falls apart in practice</h3><p>People treat blockchain as a “futuristic integrity
    wand”—wave a blockchain at the problem, and suddenly your data will be valid.
    For almost anything people want to be <em>valid</em>, blockchain has been proposed
    as a solution.</p><p>It’s true that tampering with data stored on a blockchain
    is hard, but it’s false that blockchain is a good way to create data that has
    integrity.</p><blockquote><h1>It’s true that tampering with data stored on a blockchain
    is hard, but it’s false that blockchain is a good way to create data that has
    integrity.</h1></blockquote><p>To understand why this is the case, let’s work
    from the practical to the theoretical. For example, let’s consider a widely-proposed
    use case for blockchain: buying an e-book with a “smart” contract. The goal of
    the blockchain is, you don’t trust an e-book vendor and they don’t trust you (because
    you’re just two individuals on the internet), but, because it’s on blockchain,
    you’ll be able to trust the transaction.</p><p>In the traditional system, once
    you pay you’re <em>hoping</em> you’ll receive the book, but once the vendor has
    your money they don’t have any incentive to deliver. You’re relying on Visa or
    Amazon or the government to make things fair—what a recipe for being a chump!
    In contrast, on a blockchain system, by executing the transaction as a record
    in a tamper-proof repository not owned by anyone, the transfer of money and digital
    product is automatic, atomic, and direct, with no middleman needed to arbitrate
    the transaction, dictate terms, and take a fat cut on the way. Isn’t that better
    for everybody?</p><p>Hm. Perhaps you are very skilled at writing software. When
    the novelist proposes the smart contract, you take an hour or two to make sure
    that the contract will withdraw only an amount of money equal to the agreed-upon
    price, and that the book — rather than some other file, or nothing at all — will
    actually arrive.</p><p><img src="https://cdn-images-1.medium.com/max/2480/1*t3XuYvxlgGhVlSqnhlUqSA.jpeg"
    alt="An e-book consultant"><em>An e-book consultant</em></p><p>Auditing software
    is hard! The most-heavily scrutinized smart contract in history had a small bug
    that nobody noticed — that is, until someone did notice it, and used it to steal
    fifty million dollars. If cryptocurrency enthusiasts putting together a $150m
    investment fund can’t properly audit the software, how confident are you in your
    e-book audit? Perhaps you would rather write your own counteroffer software contract,
    in case this e-book author has hidden a recursion bug in their version to drain
    your ethereum wallet of all your life savings?</p><p>It’s a complicated way to
    buy a book! It’s not <em>trustless</em>, you’re trusting in the software (and
    your ability to defend yourself in a software-driven world), instead of trusting
    other people.</p><p><img src="https://cdn-images-1.medium.com/max/4000/1*c91sjFxUObps_glZBLkMhw.jpeg"
    alt="“I’d rather look at the source code to make sure he didn’t vote twice.”"><em>“I’d
    rather look at the source code to make sure he didn’t vote twice.”</em></p><p>Another
    example: the <a href="http://web.archive.org/web/20180313084043/https://qz.com/1227050/sierra-leone-elections-powered-by-blockchain/">purported
    advantages</a> for a voting system in a weakly-governed country. “Keep your voting
    records in a tamper-proof repository not owned by anyone” <em>sounds</em> right
    — yet is your Afghan villager going to download the blockchain from a broadcast
    node and decrypt the Merkle root from his Linux command line to independently
    verify that his vote has been counted? Or will he rely on the mobile app of a
    trusted third party — like the nonprofit or open-source consortium <a href="https://qz.com/1234268/sierra-leone-blockchain-election-election-commission-denies-use-of-blockchain/">administering
    the election</a> or providing the software?</p><p>These sound like stupid examples
    — novelists and villagers hiring e-bodyguard hackers to protect them from malicious
    customers and nonprofits whose clever smart-contracts might steal their money
    and votes?? — until you realize that’s actually <em>the point</em>. Instead of
    relying on trust or regulation, in the blockchain world, individuals are <em>on-purpose</em>
    responsible for their own security precautions. And if the software they use is
    malicious or buggy, they should have read the software more carefully.</p><h3>The
    entire worldview underlying blockchain is wrong</h3><p>You actually see it over
    and over again. Blockchain systems are supposed to be <em>more</em> trustworthy,
    but in fact they are <em>the least trustworthy systems in the world</em>. Today,
    in less than a decade, <a href="https://hackernoon.com/ten-years-in-nobody-has-come-up-with-a-use-case-for-blockchain-ee98c180100#75b9">three
    successive top bitcoin exchanges</a> have been hacked, another is <a href="https://motherboard.vice.com/en_us/article/pam4xn/coinbase-insider-trading-lawsuit-gdax-bitcoin-cash">accused</a>
    of insider trading, <a href="https://hackernoon.com/ten-years-in-nobody-has-come-up-with-a-use-case-for-blockchain-ee98c180100#6aa2">the
    demonstration-project DAO smart contract got drained</a>, crypto price swings
    are ten times those of the world’s most mismanaged currencies, and bitcoin, the
    “killer app” of crypto transparency, is almost certainly<a href="http://www.tetherreport.com/">
    artificially</a> <a href="https://www.cnbc.com/2018/02/02/tether-what-you-need-to-know-about-the-cryptocurrency-worrying-markets.html">propped
    up</a> by<a href="https://hackernoon.com/the-curious-tale-of-tethers-6b0031eead87">
    fake</a> <a href="https://arstechnica.com/tech-policy/2018/02/tether-says-its-cryptocurrency-is-worth-2-billion-but-its-audit-failed/">transactions</a>
    <a href="https://www.reddit.com/r/btc/comments/7e54vo/how_is_tether_even_receiving_usd_since_the/">involving</a>
    <a href="https://cointelegraph.com/news/tether-really-isnt-a-scam-company-promises">billions</a>
    <a href="https://medium.com/@bitfinexed/the-mystery-of-the-bitfinex-tether-bank-and-why-this-is-suspicious-a8a6407a1241">of</a>
    *literally imaginary<a href="https://medium.com/@bitfinexed/">* dollars</a>.</p><p><img
    src="https://cdn-images-1.medium.com/max/3600/1*0ItJowi6v1UhgZInWFyQiA.jpeg" alt="How
    exactly does blockchain stop this guy from spraying pesticides?"><em>How exactly
    does blockchain stop this guy from spraying pesticides?</em></p><p>Blockchain
    systems do not magically make the data in them accurate or the people entering
    the data trustworthy, they merely enable you to audit whether it has been tampered
    with. A person who sprayed pesticides on a mango can still enter onto a blockchain
    system that the mangoes were organic. A corrupt government can create a blockchain
    system to count the votes and just allocate an extra million addresses to their
    cronies. An investment fund whose charter is written in software can still misallocate
    funds.</p><p>How then, is trust created?</p><p>In the case of buying an e-book,
    <em>even if you’re buying it with a smart contract,</em> instead of auditing the
    software you’ll rely on one of four things, each of them characteristics of the
    “old way”: either the author of the smart contract is someone you know of and
    trust, the seller of the e-book has a <a href="https://en.wikipedia.org/wiki/The_Evolution_of_Cooperation">reputation
    to uphold</a>, you or friends of yours have bought e-books from this seller in
    the past successfully, or you’re just willing to hope that this person will deal
    fairly. In each case, <em>even</em> if the transaction is effectuated via a smart
    contract, in practice you’re relying on trust of a counterparty or middleman,
    not your self-protective right to audit the software, each man an island unto
    himself. The contract still works, but the fact that the promise is written in
    auditable software rather than government-enforced English makes it <em>less</em>
    transparent, not <em>more</em> transparent.</p><p>The same for the vote counting.
    Before blockchain can even get involved, you need to trust that voter registration
    is done fairly, that ballots are given only to eligible voters, that the votes
    are made anonymously rather than bought or intimidated, that the vote displayed
    by the balloting system is the same as the vote recorded, and that no extra votes
    are given to the political cronies to cast. Blockchain makes none of these problems
    easier and many of them harder—but more importantly, solving them in a blockchain
    context requires a set of awkward workarounds that undermine the core premise.
    So we know the entries are valid, let’s allow only trusted nonprofits to make
    entries—and you’re back at the good old “classic” ledger. In fact, if you look
    at <em>any</em> blockchain solution, inevitably you’ll find an awkward workaround
    to re-create trusted parties in a trustless world.</p><h3>A crypto-medieval system</h3><p>Yet
    absent these “old way” factors—supposing you actually attempted to rely on blockchain’s
    self-interest/self-protection to build a real system—you’d be in a real mess.</p><p><img
    src="https://cdn-images-1.medium.com/max/2000/1*M5Yh5XByF0lkWCfUEPGW1A.jpeg" alt="The
    Knights Templar [was sort of a banking system, actually](https://en.wikipedia.org/wiki/Knights_Templar)."><em>The
    Knights Templar <a href="https://en.wikipedia.org/wiki/Knights_Templar">was sort
    of a banking system, actually</a>.</em></p><p>Eight hundred years ago in Europe
    — with weak governments unable to enforce laws and trusted counterparties few,
    fragile and far between — theft was rampant, safe banking was a fantasy, and personal
    security was at the point of the sword. This is what Somalia looks like now, and
    also, what it looks like to transact on the blockchain <em>in the ideal scenario</em>.</p><p>Somalia
    on purpose. That’s the vision. Nobody wants it!</p><p><em>Even the most die-hard
    crypto enthusiasts</em> prefer in practice to rely on trust rather than their
    own crypto-medieval systems. 93% of bitcoins are mined by managed consortiums,
    yet none of the consortiums use smart contracts to manage payouts. Instead, they<a
    href="https://slushpool.com/home/"> promise</a> things like a “long history of
    stable and accurate payouts.” Sounds like a trustworthy middleman!</p><p><img
    src="https://cdn-images-1.medium.com/max/2020/1*mDF1ET8BKW0q7XcPndQPgw.png" alt="Trusted
    sellers of stolen credit cards and cocaine."><em>Trusted sellers of stolen credit
    cards and cocaine.</em></p><p>Same with Silk Road, a cryptocurrency-driven online
    drug bazaar. The key to Silk Road wasn’t the bitcoins (that was just to evade
    government detection), it was the <em>reputation scores</em> that allowed people
    to trust criminals. And the reputation scores weren’t tracked on a tamper-proof
    blockchain, they were tracked by a trusted middleman!</p><p>If Ripple, Silk Road,
    Slush Pool, and the DAO all prefer “old way” systems of creating and enforcing
    trust, it’s no wonder that the outside world had not adopted trustless systems
    either!</p><h3>In the name of all blockchain stands for, it’s time to abandon
    blockchain</h3><p>A decentralized, tamper-proof repository sounds like a great
    way to audit where your mango comes from, how fresh it is, and whether it has
    been sprayed with pesticides or not. But actually, laws on food labeling, nonprofit
    or government inspectors, an independent, trusted free press, empowered workers
    who trust whistleblower protections, credible grocery stores, your local nonprofit
    farmer’s market, and so on, do a way better job. People who actually care about
    food safety do not adopt blockchain because <em>trusted is better than trustless.
    *Blockchain’s technology mess exposes its metaphor mess — a software engineer
    pointing out that storing the data a sequence of small hashed files won’t get
    the mango-pickers to accurately report whether they sprayed pesticides is *also</em>
    pointing out why peer-to-peer interaction with no regulations, norms, middlemen,
    or trusted parties is actually a bad way to empower people.</p><p><img src="https://cdn-images-1.medium.com/max/4096/1*eMT-ntdZqu1H6-ZJTyfYfQ.jpeg"
    alt="Smarter produce in under 2.2 seconds"><em>Smarter produce in under 2.2 seconds</em></p><p>Like
    the farmer’s market or the organic labeling standard, so many <em>real</em> ideas
    are hiding in plain sight. Do you wish there was a type of financial institution
    that was secure and well-regulated in all the traditional ways, but also has the
    integrity of being people-powered? A credit union’s members elect its directors,
    and the transaction-processing revenue is divided up among the members. Move your
    money! Prefer a deflationary monetary policy? Central bankers are appointed by
    elected leaders. Want to make elections more secure and democratic? Help write
    open source voting software, go out and register voters, or volunteer as an election
    observer here or abroad! Wish there was a trusted e-book delivery service that
    charged lower transaction fees and distributed more of the earnings to the authors?
    You can <em>already</em> consider stated payout rates when you buy music or books,
    buy directly from the authors, or start your own e-book site that’s even better
    than what’s out there!</p><p>Projects based on the elimination of trust have failed
    to capture customers’ interest <em>because trust is actually so damn valuable</em>.
    A lawless and mistrustful world where self-interest is the only principle and
    paranoia is the only source of safety is a not a paradise but a crypto-medieval
    hellhole.</p><p>As a society, and as technologists and entrepreneurs in particular,
    we’re going to have to get good at cooperating — at building trust, and, at being
    trustworthy. Instead of directing resources to the <em>elimination</em> of trust,
    we should direct our resources to the <em>creation</em> of trust—whether we use
    a long series of sequentially hashed files as our storage medium or not.</p><p><img
    src="https://cdn-images-1.medium.com/max/2000/1*dAbV-xlWARj2eZYIyFInog.png" alt=""></p><p><em>Kai
    Stinchcombe coined the terms “crypto-medieval” “futuristic integrity wand” and
    “smart mango.” Please use freely: coining terms makes you a futurist.</em></p><p><img
    src="https://cdn-images-1.medium.com/max/3916/1*QATCo0QEJYiDzVAkvy_dDA.png" alt=""></p>'
  :author: Kai Stinchcombe
  :topic_id: 728
- :url: https://netflixtechblog.com/artwork-personalization-c589f074ad76?source=search_post---------2
  :title: Artwork Personalization at Netflix
  :content: '<p>By Ashok Chandrashekar, Fernando Amat, Justin Basilico and Tony Jebara</p><p>For
    many years, the main goal of the Netflix personalized recommendation system has
    been to get the right titles in front each of our members at the right time. With
    a catalog spanning thousands of titles and a diverse member base spanning over
    a hundred million accounts, recommending the titles that are just right for each
    member is crucial. But the job of recommendation does not end there. Why should
    you care about any particular title we recommend? What can we say about a new
    and unfamiliar title that will pique your interest? How do we convince you that
    a title is worth watching? Answering these questions is critical in helping our
    members discover great content, especially for unfamiliar titles. One avenue to
    address this challenge is to consider the artwork or imagery we use to portray
    the titles. If the artwork representing a title captures something compelling
    to you, then it acts as a gateway into that title and gives you some visual “evidence”
    for why the title might be good for you. The artwork may highlight an actor that
    you recognize, capture an exciting moment like a car chase, or contain a dramatic
    scene that conveys the essence of a movie or TV show. If we present that perfect
    image on your homepage (and as they say: an image is worth a thousand words),
    then maybe, just maybe, you will give it a try. This is yet another way Netflix
    differs from traditional media offerings: we don’t have one product but over a
    100 million different products with one for each of our members with <em>personalized
    recommendations</em> and <em>personalized visuals</em>.</p><p><img src="https://cdn-images-1.medium.com/max/3200/0*038O1qN_N7lC3CGD."
    alt="A Netflix homepage without artwork. This is how historically our recommendation
    algorithms viewed a page."><em>A Netflix homepage without artwork. This is how
    historically our recommendation algorithms viewed a page.</em></p><p>In <a href="https://medium.com/netflix-techblog/selecting-the-best-artwork-for-videos-through-a-b-testing-f6155c4595f6">previous</a>
    <a href="https://media.netflix.com/en/company-blog/the-power-of-a-picture">work</a>,
    we discussed an effort to find the single perfect artwork for each title across
    <em>all</em> our members. Through multi-armed bandit algorithms, we hunted for
    the best artwork for a title, say Stranger Things, that would earn the most plays
    from the largest fraction of our members. However, given the enormous diversity
    in taste and preferences, wouldn’t it be better if we could find the best artwork
    for <em>each</em> of our members to highlight the aspects of a title that are
    specifically relevant to <em>them</em>?</p><p><img src="https://cdn-images-1.medium.com/max/2928/1*xwD8rVHPapbfmrl6AIbQbA.png"
    alt="Artwork for Stranger Things that each receive over 5% of impressions from
    our personalization algorithm. Different images cover a breadth of themes in the
    show to go beyond what any single image portrays."><em>Artwork for Stranger Things
    that each receive over 5% of impressions from our personalization algorithm. Different
    images cover a breadth of themes in the show to go beyond what any single image
    portrays.</em></p><p>As inspiration, let us explore scenarios where personalization
    of artwork would be meaningful. Consider the following examples where different
    members have different viewing histories. On the left are three titles a member
    watched in the past. To the right of the arrow is the artwork that a member would
    get for a particular movie that we recommend for them.</p><p>Let us consider trying
    to personalize the image we use to depict the movie Good Will Hunting. Here we
    might personalize this decision based on how much a member prefers different genres
    and themes. Someone who has watched many romantic movies may be interested in
    Good Will Hunting if we show the artwork containing Matt Damon and Minnie Driver,
    whereas, a member who has watched many comedies might be drawn to the movie if
    we use the artwork containing Robin Williams, a well-known comedian.</p><p><img
    src="https://cdn-images-1.medium.com/max/3200/0*yRGioOTb4-CZc6Fc." alt=""></p><p>In
    another scenario, let’s imagine how the different preferences for cast members
    might influence the personalization of the artwork for the movie Pulp Fiction.
    A member who watches many movies featuring Uma Thurman would likely respond positively
    to the artwork for Pulp Fiction that contains Uma. Meanwhile, a fan of John Travolta
    may be more interested in watching Pulp Fiction if the artwork features John.</p><p><img
    src="https://cdn-images-1.medium.com/max/3200/0*wRcWWaW0SDnT2xSI." alt=""></p><p>Of
    course, not all the scenarios for personalizing artwork are this clear and obvious.
    So we don’t enumerate such hand-derived rules but instead rely on the data to
    tell us what signals to use. Overall, by personalizing artwork we help each title
    put its best foot forward for every member and thus improve our member experience.</p><h2>Challenges</h2><p>At
    Netflix, we embrace personalization and algorithmically adapt many aspects of
    our member experience, including the <a href="https://medium.com/netflix-techblog/learning-a-personalized-homepage-aa8ec670359a">rows
    we select for the homepage</a>, the <a href="https://medium.com/netflix-techblog/netflix-recommendations-beyond-the-5-stars-part-2-d9b96aa399f5">titles
    we select for those rows</a>, the galleries we display, the messages we send,
    and so forth. Each new aspect that we personalize has unique challenges; personalizing
    the artwork we display is no exception and presents different personalization
    challenges. One challenge of image personalization is that we can <em>only</em>
    select a <em>single</em> piece of artwork to represent each title in each place
    we present it. In contrast, typical recommendation settings let us present <em>multiple
    selections</em> to a member where we can subsequently learn about their preferences
    from the item a member selects. This means that image selection is a chicken-and-egg
    problem operating in a closed loop: if a member plays a title it can only come
    from the image that we decided to present to that member. What we seek to understand
    is <em>when</em> presenting a specific piece of artwork for a title <em>influenced</em>
    a member to play (or not to play) a title and <em>when</em> a member would have
    played a title (or not) <em>regardless</em> of which image we presented. Therefore
    artwork personalization sits on top of the traditional recommendation problem
    and the algorithms need to work in conjunction with each other. Of course, to
    properly learn how to personalize artwork we need to collect <em>a lot</em> of
    data to find signals that indicate when one piece of artwork is significantly
    better for a member.</p><p>Another challenge is to understand the impact of changing
    artwork that we show a member for a title between sessions. Does changing artwork
    reduce recognizability of the title and make it difficult to visually locate the
    title again, for example if the member thought was interested before but had not
    yet watched it? Or, does changing the artwork itself lead the member to reconsider
    it due to an improved selection? Clearly, if we find better artwork to present
    to a member we should probably use it; but continuous changes can also confuse
    people. Changing images also introduces an attribution problem as it becomes unclear
    which image led a member to be interested in a title.</p><p>Next, there is the
    challenge of understanding how artwork performs in relation to other artwork we
    select in the same page or session. Maybe a bold close-up of the main character
    works for a title on a page because it stands out compared to the other artwork.
    But if every title had a similar image then the page as a whole may not seem as
    compelling. Looking at each piece of artwork in isolation may not be enough and
    we need to think about how to select a diverse set of images across titles on
    a page and across a session. Beyond the artwork for other titles, the effectiveness
    of the artwork for a title may depend on what other types of evidence and assets
    (e.g. synopses, trailers, etc.) we also display for that title. Thus, we may need
    a diverse selection where each can highlight complementary aspects of a title
    that may be compelling to a member.</p><p>To achieve effective personalization,
    we also need a good pool of artwork for each title. This means that we need several
    assets where each is engaging, informative and representative of a title to avoid
    “clickbait”. The set of images for a title also needs to be diverse enough to
    cover a wide potential audience interested in different aspects of the content.
    After all, how engaging and informative a piece of artwork is truly depends on
    the individual seeing it. Therefore, we need to have artwork that highlights not
    only different themes in a title but also different aesthetics. Our teams of artists
    and designers strive to create images that are diverse across many dimensions.
    They also take into consideration the personalization algorithms which will select
    the images during their creative process for generating artwork.</p><p>Finally,
    there are engineering challenges to personalize artwork at scale. One challenge
    is that our member experience is very visual and thus contains a lot of imagery.
    So using personalized selection for each asset means handling a peak of over 20
    million requests per second with low latency. Such a system must be robust: failing
    to properly render the artwork in our UI brings a significantly degrades the experience.
    Our personalization algorithm also needs to respond quickly when a title launches,
    which means rapidly learning to personalize in a cold-start situation. Then, after
    launch, the algorithm must continuously adapt as the effectiveness of artwork
    may change over time as both the title evolves through its life cycle and member
    tastes evolve.</p><h2>Contextual bandits approach</h2><p>Much of the Netflix recommendation
    engine is powered by machine learning algorithms. Traditionally, we collect a
    batch of data on how our members use the service. Then we run a new machine learning
    algorithm on this batch of data. Next we test this new algorithm against the current
    production system through an <a href="https://medium.com/netflix-techblog/its-all-a-bout-testing-the-netflix-experimentation-platform-4e1ca458c15">A/B
    test</a>. An A/B test helps us see if the new algorithm is better than our current
    production system by trying it out on a random subset of members. Members in group
    A get the current production experience while members in group B get the new algorithm.
    If members in group B have higher engagement with Netflix, then we roll-out the
    new algorithm to the entire member population. Unfortunately, this batch approach
    incurs regret: many members over a long period of time did not benefit from the
    better experience. This is illustrated in the figure below.</p><p><img src="https://cdn-images-1.medium.com/max/2000/0*HbJ4JXAAzT12eC05."
    alt=""></p><p><img src="https://cdn-images-1.medium.com/max/2000/0*A9oLAJuerO897OKM."
    alt=""></p><p>To reduce this regret, we move away from batch machine learning
    and consider online machine learning. For artwork personalization, the specific
    online learning framework we use is <em>contextual bandits</em>. Rather than waiting
    to collect a full batch of data, waiting to learn a model, and then waiting for
    an A/B test to conclude, contextual bandits rapidly figure out the optimal personalized
    artwork selection for a title for each member and context. Briefly, contextual
    bandits are a class of online learning algorithms that trade off the cost of gathering
    training data required for learning an unbiased model on an ongoing basis with
    the benefits of applying the learned model to each member context. In our <a href="https://medium.com/netflix-techblog/selecting-the-best-artwork-for-videos-through-a-b-testing-f6155c4595f6">previous
    unpersonalized image selection work</a>, we used non-contextual bandits where
    we found the winning image regardless of the context. For personalization, the
    member is the <em>context</em> as we expect different members to respond differently
    to the images.</p><p>A key property of contextual bandits is that they are designed
    to <em>minimize</em> regret. At a high level, the training data for a contextual
    bandit is obtained through the injection of controlled randomization in the learned
    model’s predictions. The randomization schemes can vary in complexity from simple
    epsilon-greedy formulations with uniform randomness to closed loop schemes that
    adaptively vary the degree of randomization as a function of model uncertainty.
    We broadly refer to this process as <em>data exploration</em>. The number of candidate
    artworks that are available for a title along with the size of the overall population
    for which the system will be deployed informs the choice of the data exploration
    strategy. With such exploration, we need to log information about the randomization
    for each artwork selection. This logging allows us to correct for skewed selection
    propensities and thereby perform offline model evaluation in an unbiased fashion,
    as described later.</p><p>Exploration in contextual bandits typically has a cost
    (or regret) due to the fact that our artwork selection in a member session may
    not use the predicted best image for that session. What impact does this randomization
    have on the member experience (and consequently on our metrics)? With over a hundred
    millions members, the regret incurred by exploration is typically very small and
    is amortized across our large member base with each member implicitly helping
    provide feedback on artwork for a small portion of the catalog. This makes the
    cost of exploration per member negligible, which is an important consideration
    when choosing contextual bandits to drive a key aspect of our member experience.
    Randomization and exploration with contextual bandits would be less suitable if
    the cost of exploration were high.</p><p>Under our online exploration scheme,
    we obtain a training dataset that records, for each (member, title, image) tuple,
    whether that selection resulted in a play of the title or not. Furthermore, we
    can control the exploration such that artwork selections do not change too often.
    This gives a cleaner attribution of the member’s engagement to specific artwork.
    We also carefully determine the label for each observation by looking at the quality
    of engagement to avoid learning a model that recommends “clickbait” images: ones
    that entice a member to start playing but ultimately result in low-quality engagement.</p><h3>Model
    training</h3><p>In this online learning setting, we train our contextual bandit
    model to select the best artwork for each member based on their context. We typically
    have up to a few dozen candidate artwork images per title. To learn the selection
    model, we can consider a simplification of the problem by ranking images for a
    member independently across titles. Even with this simplification we can still
    learn member image preferences across titles because, for every image candidate,
    we have some members who were presented with it and engaged with the title and
    some members who were presented with it and did not engage. These preferences
    can be modeled to predict for each (member, title, image) tuple, the probability
    that the member will enjoy a quality engagement. These can be supervised learning
    models or contextual bandit counterparts with Thompson Sampling, LinUCB, or Bayesian
    methods that intelligently balance making the best prediction with data exploration.</p><h3>Potential
    signals</h3><p>In contextual bandits, the context is usually represented as an
    feature vector provided as input to the model. There are many signals we can use
    as features for this problem. In particular, we can consider many attributes of
    the member: the titles they’ve played, the genre of the titles, interactions of
    the member with the specific title, their country, their language preferences,
    the device that the member is using, the time of day and the day of week. Since
    our algorithm selects images in conjunction with our personalized recommendation
    engine, we can also use signals regarding what our various recommendation algorithms
    think of the title, irrespective of what image is used to represent it.</p><p>An
    important consideration is that some images are naturally better than others in
    the candidate pool. We observe the overall <em>take rates</em> for all the images
    in our data exploration, which is simply the number of quality plays divided by
    the number of impressions. Our previous work on unpersonalized artwork selection
    used overall differences in take rates to determine the single best image to select
    for a whole population. In our new contextual personalized model, the overall
    take rates are still important and personalization still recovers selections that
    agree on average with the unpersonalized model’s ranking.</p><h3>Image Selection</h3><p>The
    optimal assignment of image artwork to a member is a selection problem to find
    the best candidate image from a title’s pool of available images. Once the model
    is trained as above, we use it to rank the images for each context. The model
    predicts the probability of play for a given image in a given a member context.
    We sort a candidate set of images by these probabilities and pick the one with
    the highest probability. That is the image we present to that particular member.</p><h2>Performance
    evaluation</h2><h3>Offline</h3><p>To evaluate our contextual bandit algorithms
    prior to deploying them online on real members, we can use an offline technique
    known as <em>replay</em> [<a href="https://dl.acm.org/citation.cfm?id=1935878">1</a>].
    This method allows us to answer counterfactual questions based on the logged exploration
    data (Figure 1). In other words, we can compare offline what would have happened
    in historical sessions under different scenarios if we had used different algorithms
    in an unbiased way.</p><p><img src="https://cdn-images-1.medium.com/max/3098/0*gcQNqEUdCfWMTv0i."
    alt="**Figure 1: Simple example of calculating a replay metric from logged data.
    For each member, a random image was assigned (top row). The system logged the
    impression and whether the profile played the title (green circle) or not (red
    circle). The replay metric for a new model is calculated by matching the profiles
    where the random assignment and the model assignment are the same (black square)
    and computing the take fraction over that subset.**"><strong><em>Figure 1: Simple
    example of calculating a replay metric from logged data. For each member, a random
    image was assigned (top row). The system logged the impression and whether the
    profile played the title (green circle) or not (red circle). The replay metric
    for a new model is calculated by matching the profiles where the random assignment
    and the model assignment are the same (black square) and computing the take fraction
    over that subset.</em></strong></p><p>Replay allows us to see how members would
    have engaged with our titles if we had hypothetically presented images that were
    selected through a new algorithm rather than the algorithm used in production.
    For images, we are interested in several metrics, particularly the take fraction,
    as described above. Figure 2 shows how contextual bandit approach helps increase
    the average take fraction across the catalog compared to random selection or non-contextual
    bandits.</p><p><img src="https://cdn-images-1.medium.com/max/4756/1*ROJehtHmCLHE2yI4ay0M8g.png"
    alt="**Figure 2: Average image take fraction (the higher the better) for different
    algorithms based on replay from logged image explore data. The Random (green)
    policy selects one image at random. The simple Bandit algorithm (yellow) selects
    the image with highest take fraction. Contextual Bandit algorithms (blue and pink)
    use context to select different images for different members.**"><strong><em>Figure
    2: Average image take fraction (the higher the better) for different algorithms
    based on replay from logged image explore data. The Random (green) policy selects
    one image at random. The simple Bandit algorithm (yellow) selects the image with
    highest take fraction. Contextual Bandit algorithms (blue and pink) use context
    to select different images for different members.</em></strong></p><p><img src="https://cdn-images-1.medium.com/max/2232/0*Ie2TecVCUFlyIQPb."
    alt="**Figure 3: Example of contextual image selection based on the type of profile.
    Comedy refers to a profile that mostly watches comedy titles. Similarly, Romance
    watches mostly romantic titles. The contextual bandit selects the image of Robin
    Williams, a famous comedian, for comedy-inclined profiles while selecting an image
    of a kissing couple for profiles more inclined towards romance.**"><strong><em>Figure
    3: Example of contextual image selection based on the type of profile. Comedy
    refers to a profile that mostly watches comedy titles. Similarly, Romance watches
    mostly romantic titles. The contextual bandit selects the image of Robin Williams,
    a famous comedian, for comedy-inclined profiles while selecting an image of a
    kissing couple for profiles more inclined towards romance.</em></strong></p><h3>Online</h3><p>After
    experimenting with many different models offline and finding ones that had a substantial
    increase in replay, we ultimately ran an A/B test to compare the most promising
    personalized contextual bandits against unpersonalized bandits. As we suspected,
    the personalization worked and generated a significant lift in our core metrics.
    We also saw a reasonable correlation between what we measured offline in replay
    and what we saw online with the models. The online results also produced some
    interesting insights. For example, the improvement of personalization was larger
    in cases where the member had no prior interaction with the title. This makes
    sense because we would expect that the artwork would be more important to someone
    when a title is less familiar.</p><h2>Conclusion</h2><p>With this approach, we’ve
    taken our first steps in personalizing the selection of artwork for our recommendations
    and across our service. This has resulted in a meaningful improvement in how our
    members discover new content… so we’ve rolled it out to everyone! This project
    is the first instance of personalizing not just what we recommend but also how
    we recommend to our members. But there are many opportunities to expand and improve
    this initial approach. These opportunities include developing algorithms to handle
    cold-start by personalizing new images and new titles as quickly as possible,
    for example by using techniques from computer vision. Another opportunity is extending
    this personalization approach across other types of artwork we use and other evidence
    that describe our titles such as synopses, metadata, and trailers. There is also
    an even broader problem: helping artists and designers figure out what new imagery
    we should add to the set to make a title even more compelling and personalizable.</p><p>If
    these types of challenges interest you, please let us know! We are always looking
    for great people to join our team, and, for these types of projects, we are especially
    excited by candidates with <a href="http://jobs.netflix.com/search?q=%22machine%20learning%22">machine
    learning</a> and/or <a href="http://jobs.netflix.com/search?q=%22computer%20vision%22">computer
    vision</a> expertise.</p><h2>References</h2><p>[1] L. Li, W. Chu, J. Langford,
    and X. Wang, “Unbiased Offline Evaluation of Contextual-bandit-based News Article
    Recommendation Algorithms,” in <em>Proceedings of the Fourth ACM International
    Conference on Web Search and Data Mining</em>, New York, NY, USA, 2011, pp. 297–306.</p>'
  :author: Netflix TechBlog
  :topic_id: 728
- :url: https://medium.com/airbnb-engineering/react-native-at-airbnb-the-technology-dafd0b43838?source=search_post---------3
  :title: 'React Native at Airbnb: The Technology'
  :content: '<p>The technical details</p><p><img src="https://cdn-images-1.medium.com/max/2400/1*iaYan0f1NeQlzGnwzjXEvg.jpeg"
    alt=""></p><p><em>This is the second in a <a href="https://medium.com/airbnb-engineering/react-native-at-airbnb-f95aa460be1c">series
    of blog posts</a> in which we outline our experience with React Native and what
    is next for mobile at Airbnb.</em></p><p>React Native itself is a relatively new
    and fast-moving platform in the cross-section of Android, iOS, web, and cross-platform
    frameworks. After two years, we can safely say that React Native is revolutionary
    in many ways. It is a paradigm shift for mobile and we were able to reap the benefits
    of many of its goals. However, its benefits didn’t come without significant pain
    points.</p><h2>What Worked Well</h2><h3>Cross-Platform</h3><p>The primary benefit
    of React Native is the fact that code you write runs natively on Android and iOS.
    Most features that used React Native were able to achieve <em>95–100% shared code
    *and</em> 0.2% of files were platform-specific* (<em>.android.js/</em>.ios.js).</p><h3>Unified
    Design Language System (DLS)</h3><p>We developed a cross-platform design language
    called <a href="https://airbnb.design/building-a-visual-language/">DLS</a>. We
    have Android, iOS, React Native, and web versions of every component. Having a
    unified design language was amenable to writing cross-platform features because
    it meant that designs, component names, and screens were consistent across platforms.
    However, we were still able to make platform-appropriate decisions where applicable.
    For example, we use the native <a href="https://developer.android.com/reference/android/support/v7/widget/Toolbar">Toolbar</a>
    on Android and <a href="https://developer.apple.com/documentation/uikit/uinavigationbar">UINavigationBar</a>
    on iOS and we chose to hide <a href="https://developer.apple.com/ios/human-interface-guidelines/views/tables/">disclosure
    indicators</a> on Android because they don’t adhere to the Android platform design
    guidelines.</p><p>We opted to rewrite components instead of wrapping native ones
    because it was more reliable to make platform-appropriate APIs individually for
    each platform and reduced the maintenance overhead for Android and iOS engineers
    who may not know how to properly test changes in React Native. However, it did
    cause fragmentation between the platforms in which native and React Native versions
    of the same component would get out of sync.</p><h3>React</h3><p>There is a reason
    that React is the <a href="https://insights.stackoverflow.com/survey/2018/#technology-most-loved-dreaded-and-wanted-frameworks-libraries-and-tools">most-loved</a>
    web framework. It is simple yet powerful and scales well to large codebases. Some
    of the things we particularly like are:</p><ul><li><p>*<em>Components: *</em>React
    Components enforce separation of concerns with well-defined props and state. This
    is a major contributor to React’s scalability.</p></li><li><p>*<em>Simplified
    Lifecycles: *</em>Android and, to a slightly lesser extent, iOS lifecycles are
    notoriously <a href="https://i.stack.imgur.com/fRxIQ.png">complex</a>. Functional
    reactive React components fundamentally solve this problem and made learning React
    Native dramatically simpler than learning Android or iOS.</p></li><li><p>*<em>Declarative:
    *</em>The declarative nature of React helped keep our UI in sync with the underlying
    state.</p></li></ul><h3>Iteration Speed</h3><p>While developing in React Native,
    we were able to reliably use <a href="https://facebook.github.io/react-native/blog/2016/03/24/introducing-hot-reloading.html">hot
    reloading</a> to test our changes on Android and iOS in just a second or two.
    Even though build performance is a top priority for our native apps, it has never
    come close to the iteration speed we achieved with React Native. At best, native
    compilation times are 15 seconds but can be as high as 20 minutes for full builds.</p><h3>Investing
    in Infrastructure</h3><p>We developed extensive integrations into our native infrastructure.
    All core pieces such as networking, i18n, experimentation, shared element transitions,
    device info, account info, and many others were wrapped in a single React Native
    API. These bridges were some of the more complex pieces because we wanted to wrap
    the existing Android and iOS APIs into something that was consistent and canonical
    for React. While keeping these bridges up to date with the rapid iteration and
    development of new infrastructure was a constant game of catch up, the investment
    by the infrastructure team made product work much easier.</p><p>Without this heavy
    investment in infrastructure, React Native would have led to a subpar developer
    and user experiences. As a result, we don’t believe React Native can be simply
    tacked on to an existing app without a significant and continuous investment.</p><h3>Performance</h3><p>One
    of the largest concerns around React Native was its performance. However, in practice,
    this was rarely a problem. Most of our React Native screens feel as fluid as our
    native ones. Performance is often thought of in a single dimension. We frequently
    saw mobile engineers look at JS and think “slower than Java”. However, moving
    business logic and <a href="https://github.com/facebook/yoga">layout</a> off of
    the main thread actually improves render performance in many cases.</p><p>When
    we did see performance issues, they were usually caused by excessive rendering
    and were mitigated by effectively using <a href="https://reactjs.org/docs/react-component.html#shouldcomponentupdate">shouldComponentUpdate</a>,
    <a href="https://facebook.github.io/react-native/docs/view.html#removeclippedsubviews">removeClippedSubviews</a>,
    and better use of Redux.</p><p>However, the initialization and first-render time
    (outlined below) made React Native perform poorly for launch screens, deeplinks,
    and increased the TTI time while navigating between screens. In addition, screens
    that dropped frames were difficult to debug because <a href="https://github.com/facebook/yoga">Yoga</a>
    translates between React Native components and native views.</p><h3>Redux</h3><p>We
    used <a href="https://redux.js.org/">Redux</a> for state management which we found
    effective and prevented the UI from ever getting out of sync with state and enabled
    easy data sharing across screens. However, Redux is notorious for its boilerplate
    and has a relatively difficult learning curve. We provided generators for some
    common templates but it was still one of the most challenging pieces and source
    of confusion while working with React Native. It is worth noting that these challenges
    were not React Native specific.</p><h3>Backed by Native</h3><p>Because everything
    in React Native can be bridged by native code, we were ultimately able to build
    many things we weren’t sure were possible at the beginning such as:</p><ol><li><p><em>Shared
    element transitions</em>: We built a *<SharedElement> *component that is backed
    by native shared element code on Android and iOS. This even works between native
    and React Native screens.</p></li><li><p><em>Lottie:</em> We were able to get
    Lottie working in React Native by wrapping the existing libraries on Android and
    iOS.</p></li><li><p><em>Native networking stack:</em> React Native uses our existing
    native networking stack and cache on both platforms.</p></li><li><p>*Other core
    infra: *Just like networking, we wrapped the rest of our existing native infrastructure
    such as i18n, experimentation, etc. so that it worked seamlessly in React Native.</p></li></ol><h3>Static
    Analysis</h3><p>We have a <a href="https://github.com/airbnb/javascript">strong
    history of using eslint</a> on web which we were able to leverage. However, we
    were the first platform at Airbnb to pioneer <a href="https://github.com/prettier/prettier">prettier</a>.
    We found it to be effective at reducing nits and bikeshedding on PRs. Prettier
    is now being actively investigated by our web infrastructure team.</p><p>We also
    used analytics to measure render times and performance to figure out which screens
    were the top priority to investigate for performance issues.</p><p>Because React
    Native was smaller and newer than our web infrastructure, it proved to be a good
    testbed for new ideas. Many of the tools and ideas we created for React Native
    are being adopted by web now.</p><h3>Animations</h3><p>Thanks to the React Native
    <a href="https://facebook.github.io/react-native/docs/animated.html">Animated</a>
    library, we were able to achieve jank-free animations and even interaction-driven
    animations such as scrolling parallax.</p><h3>JS/React Open Source</h3><p>Because
    React Native truly runs React and javascript, we were able to leverage the extremely
    vast array of javascript projects such as redux, reselect, jest, etc.</p><h3>Flexbox</h3><p>React
    Native handles layout with <a href="https://github.com/facebook/yoga">Yoga</a>,
    a cross-platform C library that handles layout calculations via the <a href="https://www.w3schools.com/css/css3_flexbox.asp">flexbox</a>
    API. Early on, we were hit with Yoga limitations such as the lack of aspect ratios
    but they have been added in subsequent updates. Plus, fun tutorials such as <a
    href="https://flexboxfroggy.com/">flexbox froggy</a> made onboarding more enjoyable.</p><h3>Collaboration
    with Web</h3><p>Late in the React Native exploration, we began building for web,
    iOS, and Android at once. Given that web also uses Redux, we found large swaths
    of code that could be shared across web and native platforms with no alterations.</p><h2>What
    didn’t work well</h2><h3>React Native Immaturity</h3><p>React Native is less mature
    than Android or iOS. It is newer, highly ambitious, and moving extremely quickly.
    While React Native works well in most situations, there are instances in which
    its immaturity shows through and makes something that would be trivial in native
    very difficult. Unfortunately, these instances are hard to predict and can take
    anywhere from hours to many days to work around.</p><h3>Maintaining a Fork of
    React Native</h3><p>Due to React Native’s immaturity, there were times in which
    we needed to patch the React Native source. In addition to contributing back to
    React Native, we had to <a href="https://github.com/airbnb/react-native/commits/0.46-canary">maintain
    a fork</a> in which we could quickly merge changes and bump our version. Over
    the two years, we had to add roughly 50 commits on top of React Native. This makes
    the process of upgrading React Native extremely painful.</p><h3>JavaScript Tooling</h3><p>JavaScript
    is an untyped language. The lack of type safety was both difficult to scale and
    became a point of contention for mobile engineers used to typed languages who
    may have otherwise been interested in learning React Native. We explored adopting
    <a href="https://flow.org/">flow</a> but cryptic error messages led to a frustrating
    developer experience. We also explored <a href="http://www.typescriptlang.org/">TypeScript</a>
    but integrating it into our existing infrastructure such as <a href="https://babeljs.io/">babel</a>
    and <a href="https://github.com/facebook/metro">metro bundler</a> proved to be
    problematic. However, we are continuing to actively investigate TypeScript on
    web.</p><h3>Refactoring</h3><p>A side-effect of JavaScript being untyped is that
    refactoring was extremely difficult and error-prone. Renaming props, especially
    props with a common name like <em>onClick</em> or props that are passed through
    multiple components were a nightmare to refactor accurately. To make matters worse,
    the refactors broke in production instead of at compile time and were hard to
    add proper static analysis for.</p><h3>JavaScriptCore inconsistencies</h3><p>One
    subtle and tricky aspect of React Native is due to the fact that it is executed
    on a <a href="https://facebook.github.io/react-native/docs/javascript-environment.html">JavaScriptCore
    environment</a>. The following are consequences we encountered as a result:</p><ul><li><p>iOS
    ships with its own <a href="https://developer.apple.com/documentation/javascriptcore">JavaScriptCore
    out of the box</a>. This meant that iOS was mostly consistent and not problematic
    for us.</p></li><li><p>Android doesn’t ship its own JavaScriptCore so React Native
    bundles its own. However, the one you get by default <a href="https://github.com/facebook/react-native/issues/10245">is
    ancient</a>. As a result, we had to go out of our way to bundle a <a href="https://github.com/react-community/jsc-android-buildscripts">newer
    one</a>.</p></li><li><p>While debugging, React Native attaches to a Chrome Developer
    Tools instance. This is great because it is a powerful debugger. However, once
    the debugger is attached, all JavaScript runs within Chrome’s V8 engine. This
    is fine 99.9% of the time. However, in one instance, we got bit when toLocaleString
    worked on iOS but only worked on Android while debugging. It turns out that the
    Android JSC <a href="https://github.com/facebook/react-native/issues/15717">doesn’t
    include it</a> and it was silently failing unless you were debugging in which
    case it was using V8 which does. Without knowing technical details like this,
    it can lead to days of painful debugging for product engineers.</p></li></ul><h3>React
    Native Open Source Libraries</h3><p>Learning a platform is difficult and time-consuming.
    Most people only know one or two platforms well. React Native libraries that have
    native bridges such as maps, video, etc. requires equal knowledge of all three
    platforms to be successful. We found that most React Native Open source projects
    were written by people who had experience with only one or two. This led to inconsistencies
    or unexpected bugs on Android or iOS.</p><p>On Android, many React Native libraries
    also require you to use a relative path to node_modules rather than publishing
    maven artifacts which are inconsistent with what is expected by the community.</p><h3>Parallel
    Infrastructure and Feature Work</h3><p>We have accumulated many years of native
    infrastructure on Android and iOS. However, in React Native, we started with a
    blank slate and had to write or create bridges of all existing infrastructure.
    This meant that there were times in which a product engineer needed some functionality
    that didn’t yet exist. At that point, they either had to work in a platform they
    were unfamiliar with and outside the scope of their project to build it or be
    blocked until it could be created.</p><h3>Crash Monitoring</h3><p>We use <a href="https://www.bugsnag.com/">Bugsnag</a>
    for crash reporting on Android and iOS. While we were able to get Bugsnag generally
    working on both platforms, it was less reliable and required more work than it
    did on our other platforms. Because React Native is relatively new and rare in
    the industry, we had to build a significant amount of infrastructure such as uploading
    source maps in-house and had to work with Bugsnag to be able to do things like
    filter crashes by just those that occurred in React Native.</p><p>Due to the amount
    of custom infrastructure around React Native, we would occasionally have serious
    issues in which crashes weren’t reported or source maps weren’t properly uploaded.</p><p>Finally,
    debugging React Native crashes were often more challenging if the issue spanned
    React Native and native code since stack traces don’t jump between React Native
    and native.</p><h3>Native Bridge</h3><p>React Native has a <a href="https://facebook.github.io/react-native/docs/communication-ios.html">bridge
    API</a> to communicate between native and React Native. While it works as expected,
    it is extremely cumbersome to write. Firstly, it requires all three development
    environments to be properly set up. We also experienced many issues in which the
    types coming from JavaScript were unexpected. For example, integers were often
    wrapped by strings, an issue that isn’t realized until it is passed over a bridge.
    To make matters worse, sometimes iOS will fail silently while Android will crash.
    We began to investigate automatically generating bridge code from TypeScript definitions
    towards the end of 2017 but it was too little too late.</p><h3>Initialization
    Time</h3><p>Before React Native can render for the first time, you must initialize
    its runtime. Unfortunately, this takes several seconds for an app of our size,
    even on a high-end device. This made using React Native for launch screens nearly
    impossible. We minimized the first-render time for React Native by initializing
    it at app-launch.</p><h3>Initial Render Time</h3><p>Unlike with native screens,
    rendering React Native requires at least one full main thread -&gt; js -&gt; yoga
    layout thread -&gt; main thread round trip before there is enough information
    to render a screen for the first time. We saw an average initial p90 render of
    280ms on iOS and 440ms on Android. On Android, we used the <a href="https://developer.android.com/reference/android/app/Activity.html#postponeEnterTransition()">postponeEnterTransition</a>
    API which is normally used for shared element transitions to delay showing the
    screen until it has rendered. On iOS, we had issues setting the navbar configuration
    from React Native fast enough. As a result, we added an artificial delay of 50ms
    to all React Native screen transitions to prevent the navbar from flickering once
    the configuration was loaded.</p><h3>App Size</h3><p>React Native also has a non-negligible
    impact on app size. On Android, the total size of React Native (Java + JS + native
    libraries such as Yoga + Javascript Runtime) was 8mb per ABI. With both x86 and
    arm (32 bit only) in one APK, it would have been closer to 12mb.</p><h3>64-bit</h3><p>We
    still can’t ship a 64-bit APK on Android because of <a href="https://github.com/facebook/react-native/issues/2814">this</a>
    issue.</p><h3>Gestures</h3><p>We avoided using React Native for screens that involved
    complex gestures because the touch subsystem for Android and iOS are different
    enough that coming up with a unified API has been challenging for the entire React
    Native community. However, work is continuing to progress and <a href="https://github.com/kmagiera/react-native-gesture-handler">react-native-gesture-handler</a>
    just hit 1.0.</p><h3>Long Lists</h3><p>React Native has made some progress in
    this area with libraries like <a href="https://facebook.github.io/react-native/docs/flatlist.html">FlatList</a>.
    However, they are nowhere near the maturity and flexibility of <a href="https://developer.android.com/guide/topics/ui/layout/recyclerview">RecyclerView</a>
    on Android or <a href="https://developer.apple.com/documentation/uikit/uicollectionview">UICollectionView</a>
    on iOS. Many of the limitations are difficult to overcome because of the threading.
    Adapter data can’t be accessed synchronously so it is possible to see views flash
    in as they get asynchronously rendered while scrolling quickly. Text also can’t
    be measured synchronously so iOS can’t make certain optimizations with pre-computed
    cell heights.</p><h3>Upgrading React Native</h3><p>Although most React Native
    upgrades were trivial, there were a few that wound up being painful. In particular,
    it was nearly impossible to use React Native 0.43 (April 2017) to 0.49 (October
    2017) because it used React 16 alpha and beta. This was hugely problematic because
    most React libraries that are designed for web use don’t support pre-release React
    versions. The process of wrangling the proper dependencies for this upgrade was
    a major detriment to other React Native infrastructure work in mid-2017.</p><h3>Accessibility</h3><p>In
    2017, we did a major <a href="https://airbnb.design/designing-for-access/">accessibility
    overhaul</a> in which we invested significant efforts to ensure that people with
    disabilities can use Airbnb to book a listing that can accommodate their needs.
    However, there were many holes in the React Native accessibility APIs. In order
    to meet even a minimum acceptable accessibility bar, we had to <a href="https://github.com/airbnb/react-native/commits/0.46-canary">maintain
    our own fork</a> of React Native where we could merge fixes. For these case, a
    one-line fix on Android or iOS wound up taking days of figuring out how to add
    it to React Native, cherry picking it, then filing an issue on React Native core
    and following up on it over the coming weeks.</p><h3>Troublesome Crashes</h3><p>We
    have had to deal with a few very bizarre crashes that are hard to fix. For example,
    we are currently experiencing <a href="https://issuetracker.google.com/issues/37045084">this
    crash</a> on the <em>@ReactProp</em> annotation and have been unable to reproduce
    it on any device, even those with identical hardware and software to ones that
    are crashing in the wild.</p><h3>SavedInstanceState Across Processes on Android</h3><p>Android
    frequently cleans up background processes but gives them a chance to <a href="https://developer.android.com/topic/libraries/architecture/saving-states#use_onsaveinstancestate_as_backup_to_handle_system_initiated_process_death">synchronously
    save their state in a bundle</a>. However, on React Native, all state is only
    accessible in the js thread so this can’t be done synchronously. Even if this
    weren’t the case, redux as a state store is not compatible with this approach
    because it contains a mix of serializable and non-serializable data and may contain
    more data than can fit within the savedInstanceState bundle which would lead to
    <a href="https://medium.com/@mdmasudparvez/android-os-transactiontoolargeexception-on-nougat-solved-3b6e30597345">crashes
    in production</a>.</p><p>This is part two in a series of blog posts highlighting
    our experiences with React Native and what’s next for mobile at Airbnb.</p><ul><li><p><a
    href="https://medium.com/airbnb-engineering/react-native-at-airbnb-f95aa460be1c">Part
    1: React Native at Airbnb</a></p></li><li><p><a href="https://medium.com/airbnb-engineering/react-native-at-airbnb-the-technology-dafd0b43838">*Part
    2: The Technology</a>*</p></li><li><p><a href="https://medium.com/airbnb-engineering/building-a-cross-platform-mobile-team-3e1837b40a88">Part
    3: Building a Cross-Platform Mobile Team</a></p></li><li><p><a href="https://medium.com/airbnb-engineering/sunsetting-react-native-1868ba28e30a">Part
    4: Making a Decision on React Native</a></p></li><li><p><a href="https://medium.com/airbnb-engineering/whats-next-for-mobile-at-airbnb-5e71618576ab">Part
    5: What’s Next for Mobile</a></p></li></ul>'
  :author: Airbnb Engineering & Data Science
  :topic_id: 728
- :url: https://medium.com/@cdixon/eleven-reasons-to-be-excited-about-the-future-of-technology-ef5f9b939cb2?source=search_post---------4
  :title: Eleven Reasons To Be Excited About The Future of Technology
  :content: '<p>“The strongest force propelling human progress has been the swift
    advance and wide diffusion of technology.” — The Economist</p><p>In the year 1820,
    a person could <a href="https://ourworldindata.org/life-expectancy/">expect to
    live</a> less than 35 years, 94% of the global population <a href="https://ourworldindata.org/world-poverty/">lived
    in extreme poverty</a>, and less that 20% of the population was literate. Today,
    human life expectancy is over 70 years, less that 10% of the global population
    lives in extreme poverty, and <a href="http://www.oecd.org/statistics/How-was-life.pdf">over
    80% of people</a> are literate. These improvements are due mainly to advances
    in technology, beginning in the industrial age and continuing today in the information
    age.</p><p>There are many exciting new technologies that will continue to transform
    the world and improve human welfare. Here are eleven of them.</p><h2>1. Self-Driving
    Cars</h2><p>Self-driving cars exist today that are safer than human-driven cars
    in most driving conditions. Over the next 3–5 years they‘ll get even safer, and
    will begin to go mainstream.</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*HfoJs9tCyyr6VeLvD45wyQ.gif"
    alt=""></p><p>The <a href="http://www.who.int/mediacentre/factsheets/fs358/en/">World
    Health Organization estimates</a> that 1.25 million people die from car-related
    injuries per year. Half of the deaths are pedestrians, bicyclists, and motorcyclists
    hit by cars. Cars are the leading cause of death for people ages 15–29 years old.</p><p><img
    src="https://cdn-images-1.medium.com/max/2000/1*SNGdeK4GNUhjL6wlh7sfJw.png" alt=""></p><p>Just
    as cars reshaped the world in the 20th century, so will self-driving cars in the
    21st century. In most cities, <a href="http://oldurbanist.blogspot.com.es/2011/12/we-are-25-looking-at-street-area.html">between
    20–30%</a> of usable space is taken up by parking spaces, and most cars are parked
    <a href="http://www.reinventingparking.org/2013/02/cars-are-parked-95-of-time-lets-check.html">about
    95%</a> of the time. Self-driving cars will be in almost continuous use (most
    likely hailed from a smartphone app), thereby dramatically reducing the need for
    parking. Cars will communicate with one another to avoid accidents and traffic
    jams, and riders will be able to spend commuting time on other activities like
    work, education, and socializing.</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*k6w2wkkREpVeu9_cS2xxtg.png"
    alt="Source: [Tech Insider](http://www.techinsider.io/chris-dixon-future-of-self-driving-cars-interview-2016-6)"><em>Source:
    <a href="http://www.techinsider.io/chris-dixon-future-of-self-driving-cars-interview-2016-6">Tech
    Insider</a></em></p><h2>2. Clean Energy</h2><p>Attempts to fight climate change
    by reducing the demand for energy <a href="https://en.wikipedia.org/wiki/World_energy_consumption">haven’t
    worked</a>. Fortunately, scientists, engineers, and entrepreneurs have been working
    hard on the supply side to make clean energy convenient and cost-effective.</p><p>Due
    to steady technological and manufacturing advances, the price of solar cells has
    <a href="http://www.saskwind.ca/wind-cost-decline/">dropped 99.5% since 1977</a>.
    Solar will soon be more cost efficient than fossil fuels. The cost of wind energy
    has also dropped to an all-time low, and in the last decade represented about
    a <a href="http://energy.gov/articles/top-10-things-you-didnt-know-about-wind-power">third
    of newly installed</a> US energy capacity.</p><p>Forward thinking organizations
    are taking advantage of this. For example, in India there is an initiative to
    convert airports to self-sustaining clean energy.</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*idAW1ONI_iIeevzPaUv-pg.png"
    alt="Airport in Kochi, India (source: [Clean Technica](http://cleantechnica.com/2015/08/21/1st-airport-world-go-100-solar-india/))"><em>Airport
    in Kochi, India (source: <a href="http://cleantechnica.com/2015/08/21/1st-airport-world-go-100-solar-india/">Clean
    Technica</a>)</em></p><p>Tesla is making high-performance, affordable electric
    cars, and <a href="http://www.treehugger.com/cars/tesla-built-858-new-charging-stations-us-over-past-12-months.html">installing</a>
    electric charging stations <a href="http://mashable.com/2016/04/01/tesla-supercharger-expansion/#v93tzyDFl5qR">worldwide</a>.</p><p><img
    src="https://cdn-images-1.medium.com/max/2000/1*YwcTRiWETVn4aXiZhEJtcg.png" alt="Tesla
    Model 3 and US supercharger locations"><em>Tesla Model 3 and US supercharger locations</em></p><p>There
    are hopeful signs that clean energy could soon be reaching a tipping point. For
    example, in Japan, there are now more electric charging stations than gas stations.</p><p><img
    src="https://cdn-images-1.medium.com/max/2000/1*RNmY6abYWA2n2W6EgP3lcA.png" alt="Source:
    [The Guardian](https://www.theguardian.com/world/2016/may/10/japan-electric-car-charge-points-petrol-stations)"><em>Source:
    <a href="https://www.theguardian.com/world/2016/may/10/japan-electric-car-charge-points-petrol-stations">The
    Guardian</a></em></p><p>And Germany produces so much renewable energy, it sometimes
    produces even more than it can use.</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*wETYiSDThJ5fQYIVWuw8aA.png"
    alt="Source: [Time Magazine](http://time.com/4325882/german-renewable-energy-high/)"><em>Source:
    <a href="http://time.com/4325882/german-renewable-energy-high/">Time Magazine</a></em></p><h2>3.
    Virtual and Augmented Reality</h2><p>Computer processors only recently became
    fast enough to power comfortable and convincing virtual and augmented reality
    experiences. Companies like Facebook, Google, Apple, and Microsoft are investing
    billions of dollars to make VR and AR more immersive, comfortable, and affordable.</p><p><img
    src="https://cdn-images-1.medium.com/max/2000/1*6cmd8P-bPYRU1olrJHsvfw.gif" alt="Toybox
    demo from Oculus"><em>Toybox demo from Oculus</em></p><p>People sometimes think
    VR and AR will be used only for gaming, but over time they will be used for all
    sorts of activities. For example, we’ll use them to manipulate 3-D objects:</p><p><img
    src="https://cdn-images-1.medium.com/max/2000/1*q_pqQCTcTETf4G-ARUm00A.jpeg" alt="Augmented
    reality computer interface (from [Iron Man](http://www.imdb.com/title/tt0371746/))"><em>Augmented
    reality computer interface (from <a href="http://www.imdb.com/title/tt0371746/">Iron
    Man</a>)</em></p><p>To meet with friends and colleagues from around the world:</p><p><img
    src="https://cdn-images-1.medium.com/max/2000/1*MJcHcqCWEzGxDIVDGpcHcA.jpeg" alt="Augmented
    reality teleconference (from [The Kingsman](http://www.imdb.com/title/tt2802144/))"><em>Augmented
    reality teleconference (from <a href="http://www.imdb.com/title/tt2802144/">The
    Kingsman</a>)</em></p><p>And even for medical applications, like treating phobias
    or helping rehabilitate paralysis victims:</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*q_J7Ql2iVfdDYc5t6hM98Q.png"
    alt="Source: [New Scientist](https://www.newscientist.com/article/2100780-virtual-reality-helps-eight-paralysed-people-feel-their-legs/)"><em>Source:
    <a href="https://www.newscientist.com/article/2100780-virtual-reality-helps-eight-paralysed-people-feel-their-legs/">New
    Scientist</a></em></p><p>VR and AR have been dreamed about by science fiction
    fans for decades. In the next few years, they’ll finally become a mainstream reality.</p><h2>4.
    Drones and Flying Cars</h2><blockquote><h1>“Roads? Where we’re going we don’t
    need… roads.” — Dr. Emmet Brown</h1></blockquote><p>GPS started out as a military
    technology but is now used to hail taxis, get mapping directions, and hunt Pokémon.
    Likewise, drones started out as a military technology, but are increasingly being
    used for a wide range of consumer and commercial applications.</p><p>For example,
    drones are being used to inspect critical infrastructure like bridges and power
    lines, to survey areas struck by natural disasters, and many other creative uses
    like fighting animal poaching.</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*hLhAdWXECMyNLwrHfad6pA.png"
    alt="Source: [NBC News](http://www.nbcnews.com/news/world/air-shepherd-uses-drones-stop-elephant-rhino-poachers-africa-n335801)"><em>Source:
    <a href="http://www.nbcnews.com/news/world/air-shepherd-uses-drones-stop-elephant-rhino-poachers-africa-n335801">NBC
    News</a></em></p><p>Amazon and Google are building drones to deliver household
    items.</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*s1eQciCtoaD_AaovzJouAA.gif"
    alt="Amazon delivery drone"><em>Amazon delivery drone</em></p><p>The startup <a
    href="http://flyzipline.com/product/">Zipline</a> uses drones to deliver medical
    supplies to remote villages that can’t be accessed by roads.</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*BDepNtZOTWXNOi5F4Dk3Dg.png"
    alt="Source: [The Verge](http://www.theverge.com/2016/8/2/12350274/zipline-drone-delivery-us-launch-blood-medicine)"><em>Source:
    <a href="http://www.theverge.com/2016/8/2/12350274/zipline-drone-delivery-us-launch-blood-medicine">The
    Verge</a></em></p><p>There is also a new wave of startups working on flying cars
    (including <a href="http://www.bloomberg.com/news/articles/2016-06-09/welcome-to-larry-page-s-secret-flying-car-factories">two</a>
    funded by the cofounder of Google, Larry Page).</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*FJyVIp3MI_k7mVM5obpSsA.png"
    alt="The Terrafugia TF-X flying car ([source](https://thestack.com/world/2015/12/18/flying-car-receives-u-s-airspace-approval-for-testing/))"><em>The
    Terrafugia TF-X flying car (<a href="https://thestack.com/world/2015/12/18/flying-car-receives-u-s-airspace-approval-for-testing/">source</a>)</em></p><p>Flying
    cars use the same advanced technology used in drones but are large enough to carry
    people. Due to advances in materials, batteries, and software, flying cars will
    be significantly more affordable and convenient than today’s planes and helicopters.</p><h2>5.
    Artificial Intelligence</h2><p><img src="https://cdn-images-1.medium.com/max/2000/1*I2dRn7D8ZZM7nI2IvvMFDw.jpeg"
    alt=""></p><blockquote><p>‘’It may be a hundred years before a computer beats
    humans at Go — maybe even longer.” — <a href="http://www.nytimes.com/1997/07/29/science/to-test-a-powerful-computer-play-an-ancient-game.html?pagewanted=all">New
    York Times, 1997</a>“Master of Go Board Game Is Walloped by Google Computer Program”
    —<a href="http://www.nytimes.com/2016/03/10/world/asia/google-alphago-lee-se-dol.html">
    New York Times, 2016</a></p></blockquote><p>Artificial intelligence has made rapid
    advances in the last decade, due to new algorithms and massive increases in data
    collection and computing power.</p><p>AI can be applied to almost any field. For
    example, in photography an AI technique called artistic style transfer transforms
    photographs into the style of a given painter:</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*aHFJuj-jhnP4zHY1dD7tRA.png"
    alt="[Source](https://no2147483647.wordpress.com/2015/12/21/deep-learning-for-hackers-with-mxnet-2/)"><em><a
    href="https://no2147483647.wordpress.com/2015/12/21/deep-learning-for-hackers-with-mxnet-2/">Source</a></em></p><p>Google
    built an AI system that controls its datacenter power systems, saving hundreds
    of millions of dollars in energy costs.</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*HpTNGOsV1a0PpqjQZNXKEQ.png"
    alt="Source: [Bloomberg](http://www.bloomberg.com/news/articles/2016-07-19/google-cuts-its-giant-electricity-bill-with-deepmind-powered-ai)"><em>Source:
    <a href="http://www.bloomberg.com/news/articles/2016-07-19/google-cuts-its-giant-electricity-bill-with-deepmind-powered-ai">Bloomberg</a></em></p><p>The
    broad promise of AI is to liberate people from repetitive mental tasks the same
    way the industrial revolution liberated people from repetitive physical tasks.</p><blockquote><p>“If
    AI can help humans become better chess players, it stands to reason that it can
    help us become better pilots, better doctors, better judges, better teachers.”
    — <a href="http://www.wired.com/2014/10/future-of-artificial-intelligence/">Kevin
    Kelly</a></p></blockquote><p>Some people worry that AI will destroy jobs. History
    has shown that while new technology does indeed eliminate jobs, it also creates
    new and better jobs to replace them. For example, with advent of the personal
    computer, the number of typographer jobs dropped, but the increase in graphic
    designer jobs more than made up for it.</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*c_lt2s5TuSoOfmPb_Rv46w.png"
    alt="Source: [Harvard Business Review](https://hbr.org/2016/03/computers-dont-kill-jobs-but-do-increase-inequality)"><em>Source:
    <a href="https://hbr.org/2016/03/computers-dont-kill-jobs-but-do-increase-inequality">Harvard
    Business Review</a></em></p><p>It is much easier to imagine jobs that will go
    away than new jobs that will be created. Today millions of people work as app
    developers, ride-sharing drivers, drone operators, and social media marketers—
    jobs that didn’t exist and would have been difficult to even imagine ten years
    ago.</p><h2>6. Pocket Supercomputers for Everyone</h2><p><img src="https://cdn-images-1.medium.com/max/2000/1*5tt6F_Cxnf5n7J5v6Lx0Ug.png"
    alt=""></p><p>By 2020, 80% of adults on earth <a href="">will have</a> an internet-connected
    smartphone. An iPhone 6 has about 2 billion transistors, roughly 625 times more
    transistors than a 1995 Intel Pentium computer. Today’s smartphones are what used
    to be considered supercomputers.</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*vovBLv3ePKce3dPrU3q9Lg.png"
    alt="Visitors to the pope (source: [Business Insider](http://www.businessinsider.com/vatican-square-2005-and-2013-2013-3))"><em>Visitors
    to the pope (source: <a href="http://www.businessinsider.com/vatican-square-2005-and-2013-2013-3">Business
    Insider</a>)</em></p><p>Internet-connected smartphones give ordinary people abilities
    that, just a short time ago, were only available to an elite few:</p><blockquote><p>“Right
    now, a Masai warrior on a mobile phone in the middle of Kenya has better mobile
    communications than the president did 25 years ago. If he’s on a smart phone using
    Google, he has access to more information than the U.S. president did just 15
    years ago.” — <a href="http://edition.cnn.com/2012/05/06/opinion/diamandis-abundance-innovation/">Peter
    Diamandis</a></p></blockquote><h2>7. Cryptocurrencies and Blockchains</h2><blockquote><h1>“If
    you asked people in 1989 what they needed to make their life better, it was unlikely
    that they would have said a decentralized network of information nodes that are
    linked using hypertext.” — <a href="http://farmerandfarmer.org/mastery/builder.html">Farmer
    &amp; Farmer</a></h1></blockquote><p>Protocols are the plumbing of the internet.
    Most of the protocols we use today were developed decades ago by academia and
    government. Since then, protocol development mostly stopped as energy shifted
    to developing proprietary systems like social networks and messaging apps.</p><p>Cryptocurrency
    and blockchain technologies are <a href="http://avc.com/2016/07/the-golden-age-of-open-protocols/">changing
    this</a> by providing a new business model for internet protocols. This year alone,
    <a href="https://medium.com/the-coinbase-blog/app-coins-and-the-dawn-of-the-decentralized-business-model-8b8c951e734f#.2atvp1cxd">hundreds
    of millions of dollars</a> were raised for a broad range of innovative blockchain-based
    protocols.</p><p>Protocols based on blockchains also have capabilities that previous
    protocols didn’t. For example, <a href="https://en.wikipedia.org/wiki/Ethereum">Ethereum</a>
    is a new blockchain-based protocol that can be used to create smart contracts
    and trusted databases that are immune to corruption and censorship.</p><h2>8.
    High-Quality Online Education</h2><p>While college tuition <a href="http://www.cnbc.com/2015/06/16/why-college-costs-are-so-high-and-rising.html">skyrockets</a>,
    anyone with a smartphone can study almost any topic online, accessing educational
    content that is mostly free and increasingly high-quality.</p><p>Encyclopedia
    Britannica <a href="http://www.csmonitor.com/Business/Latest-News-Wires/2012/0314/Encyclopaedia-Britannica-After-244-years-in-print-only-digital-copies-sold">used
    to cost $1,400</a>. Now anyone with a smartphone can instantly access Wikipedia.
    You used to have to go to school or buy programming books to learn computer programming.
    Now you can learn from a community of over 40 million programmers at <a href="http://stackoverflow.com">Stack
    Overflow</a>. YouTube has millions of hours of free tutorials and lectures, many
    of which are produced by top professors and universities.</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*NZTqnqYbOPv6sf7gCVLz8g.png"
    alt="UC Berkeley Physics on [Youtube](https://www.youtube.com/user/UCBerkeley/videos?sort=p&amp;view=0&amp;flow=list)"><em>UC
    Berkeley Physics on <a href="https://www.youtube.com/user/UCBerkeley/videos?sort=p&view=0&flow=list">Youtube</a></em></p><p>The
    quality of online education is getting better all the time. For the last 15 years,
    <a href="http://ocw.mit.edu/index.htm">MIT has been recording lectures</a> and
    compiling materials that cover over 2000 courses.</p><blockquote><p>“The idea
    is simple: to publish all of our course materials online and make them widely
    available to everyone.” — Dick K.P. Yue, Professor, MIT School of Engineering</p></blockquote><p>As
    perhaps the greatest research university in the world, MIT has always been ahead
    of the trends. Over the next decade, expect many other schools to follow MIT’s
    lead.</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*W-i0QTotXS-K4MU9qbpylQ.png"
    alt="Source: [Futurism](http://futurism.com/free-ivy-league-education-access-over-2000-classes-from-mit-for-nothing/)"><em>Source:
    <a href="http://futurism.com/free-ivy-league-education-access-over-2000-classes-from-mit-for-nothing/">Futurism</a></em></p><h2>9.
    Better Food through Science</h2><p><img src="https://cdn-images-1.medium.com/max/2000/1*O5VQyJRhI2-sHYzZPrHSBQ.png"
    alt="Source: [National Geographic](http://environment.nationalgeographic.com/environment/freshwater/embedded-water/)"><em>Source:
    <a href="http://environment.nationalgeographic.com/environment/freshwater/embedded-water/">National
    Geographic</a></em></p><p>Earth is running out of farmable land and fresh water.
    This is partly because our food production systems are incredibly inefficient.
    It takes an astounding 1799 gallons of water to produce 1 pound of beef.</p><p>Fortunately,
    a variety of new technologies are being developed to improve our food system.</p><p>For
    example, entrepreneurs are developing new food products that are tasty and nutritious
    substitutes for traditional foods but far more environmentally friendly. The startup
    <a href="http://www.impossiblefoods.com/">Impossible Foods</a> invented meat products
    that look and taste like the real thing but are actually made of plants.</p><p><img
    src="https://cdn-images-1.medium.com/max/2000/1*bUV4b3Xp0mvvdA8dp1hMtA.png" alt="Impossible
    Food’s plant-based burger (source: [Tech Insider](http://www.techinsider.io/the-impossible-foods-burger-review-vegetarian-2016-8))"><em>Impossible
    Food’s plant-based burger (source: <a href="http://www.techinsider.io/the-impossible-foods-burger-review-vegetarian-2016-8">Tech
    Insider</a>)</em></p><p>Their burger <a href="http://www.impossiblefoods.com/our-burger">uses</a>
    95% less land, 74% less water, and produces 87% less greenhouse gas emissions
    than traditional burgers. Other startups are creating plant-based replacements
    for <a href="http://ripplefoods.com/">milk</a>, <a href="https://www.hamptoncreek.com/">eggs</a>,
    and other common foods. <a href="http://soylent.com/">Soylent</a> is a healthy,
    inexpensive meal replacement that uses advanced engineered <a href="http://terravia.com/Terravia_Sustainability.pdf">ingredients</a>
    that are much friendlier to the environment than traditional ingredients.</p><p>Some
    of these products are developed using genetic modification, a powerful scientific
    technique that has been widely mischaracterized as dangerous. According to a <a
    href="https://www.geneticliteracyproject.org/2015/01/29/pewaaas-study-scientific-consensus-on-gmo-safety-stronger-than-for-global-warming/">study</a>
    by the Pew Organization, 88% of scientists think genetically modified foods are
    safe.</p><p>Another exciting development in food production is automated indoor
    farming. Due to advances in solar energy, sensors, lighting, robotics, and artificial
    intelligence, indoor farms have become viable alternatives to traditional outdoor
    farms.</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*0Jyjlgj1KU2yfBqo7quCLQ.png"
    alt="Aerofarms indoor farm (Source: [New York Times](http://www.nytimes.com/2016/07/24/nyregion/food-produced-by-the-high-tech-urban-farming-reaches-new-heights.html?_r=1))"><em>Aerofarms
    indoor farm (Source: <a href="http://www.nytimes.com/2016/07/24/nyregion/food-produced-by-the-high-tech-urban-farming-reaches-new-heights.html?_r=1">New
    York Times</a>)</em></p><p>Compared to traditional farms, automated indoor farms
    use roughly 10 times less water and land. Crops are harvested many more times
    per year, there is no dependency on weather, and no need to use pesticides.</p><h2>10.
    Computerized Medicine</h2><p>Until recently, computers have only been at the periphery
    of medicine, used primarily for research and record keeping. Today, the combination
    of computer science and medicine is leading to a variety of breakthroughs.</p><p><img
    src="https://cdn-images-1.medium.com/max/2000/1*IjKrWZdlbB2ksis_Dmia5A.png" alt=""></p><p>For
    example, just fifteen years ago, it cost $3B to sequence a human genome. Today,
    the cost is about a thousand dollars and continues to drop. Genetic sequencing
    will soon be a routine part of medicine.</p><p>Genetic sequencing generates massive
    amounts of data that can be analyzed using powerful data analysis software. One
    application is analyzing <a href="http://a16z.com/2016/06/09/freenome/">blood
    samples</a> for early detection of cancer. Further genetic analysis can help determine
    the <a href="http://www.businessinsider.com/super-cheap-genome-sequencing-by-2020-2014-10">best
    course</a> of treatment.</p><p>Another application of computers to medicine is
    in prosthetic limbs. Here a young girl is using prosthetic hands she controls
    using her upper-arm muscles:</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*jVH1wxchOJ5qJzT46s907A.gif"
    alt="Source: [Open Bionics](https://twitter.com/openbionics/status/755691739147538432)"><em>Source:
    <a href="https://twitter.com/openbionics/status/755691739147538432">Open Bionics</a></em></p><p>Soon
    we’ll have the technology to control prothetic limbs with just our thoughts using
    <a href="http://news.uci.edu/feature/to-walk-again/">brain-to-machine interfaces</a>.</p><p>Computers
    are also becoming increasingly effective at diagnosing diseases. An artificial
    intelligence system recently diagnosed a rare disease that human doctors failed
    to diagnose by finding hidden patterns in 20 million cancer records.</p><p><img
    src="https://cdn-images-1.medium.com/max/2000/1*OEgWlj9sp2mCV0PrT9yp8A.png" alt="Source:
    [International Business Times](http://www.ibtimes.co.uk/ibms-watson-cracks-medical-mystery-life-saving-diagnosis-patient-who-baffled-doctors-1574963)"><em>Source:
    <a href="http://www.ibtimes.co.uk/ibms-watson-cracks-medical-mystery-life-saving-diagnosis-patient-who-baffled-doctors-1574963">International
    Business Times</a></em></p><h2>11.** A New Space Age**</h2><p>Since the beginning
    of the space age in the 1950s, the vast majority of space funding has come from
    governments. But that funding has been in decline: for example, NASA’s budget
    <a href="https://en.wikipedia.org/wiki/Budget_of_NASA">dropped</a> from about
    4.5% of the federal budget in the 1960s to about 0.5% of the federal budget today.</p><p><img
    src="https://cdn-images-1.medium.com/max/2000/1*paniidrx59zPQjq_q6rUHA.png" alt="Source:
    [Fortune](http://fortune.com/2016/02/22/vcs-invested-more-in-space-startups-last-year/)"><em>Source:
    <a href="http://fortune.com/2016/02/22/vcs-invested-more-in-space-startups-last-year/">Fortune</a></em></p><p>The
    good news is that private space companies have started filling the void. These
    companies provide a wide range of products and services, including rocket launches,
    scientific research, communications and imaging satellites, and emerging speculative
    business models like asteroid mining.</p><p>The most famous private space company
    is Elon Musk’s SpaceX, which successfully sent rockets into space that can return
    home to be reused.</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*5iiaQsTBu1tQ_hTy8fupXg.gif"
    alt="SpaceX Falcon 9 [landing](https://www.youtube.com/watch?v=_ZXu_rYF51M)"><em>SpaceX
    Falcon 9 <a href="https://www.youtube.com/watch?v=_ZXu_rYF51M">landing</a></em></p><p>Perhaps
    the most intriguing private space company is <a href="http://www.planetaryresources.com/">Planetary
    Resources</a>, which is trying to pioneer a new industry: mining minerals from
    asteroids.</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*6zvea6z14lJ6inZQsVBsBA.png"
    alt="[Asteroid mining](https://www.youtube.com/watch?v=n9EMcyfGMDA)"><em><a href="https://www.youtube.com/watch?v=n9EMcyfGMDA">Asteroid
    mining</a></em></p><p>If successful, asteroid mining could lead to a new gold
    rush in outer space. Like previous gold rushes, this could lead to speculative
    excess, but also dramatically increased funding for new technologies and infrastructure.</p><p>These
    are just a few of the amazing technologies we’ll see developed in the coming decades.
    2016 is just the beginning of a new age of wonders. As futurist Kevin Kelly <a
    href="https://www.linkedin.com/pulse/internet-still-beginning-its-kevin-kelly">says</a>:</p><blockquote><p>If
    we could climb into a time machine, journey 30 years into the future, and from
    that vantage look back to today, we’d realize that most of the greatest products
    running the lives of citizens in 2050 were not invented until after 2016. People
    in the future will look at their holodecks and wearable virtual reality contact
    lenses and downloadable avatars and AI interfaces and say, “Oh, you didn’t really
    have the internet” — or whatever they’ll call it — “back then.”So, the truth:
    Right now, today, in 2016 is the best time to start up. There has never been a
    better day in the whole history of the world to invent something. There has never
    been a better time with more opportunities, more openings, lower barriers, higher
    benefit/ risk ratios, better returns, greater upside than now. Right now, this
    minute. This is the moment that folks in the future will look back at and say,
    “Oh, to have been alive and well back then!”</p></blockquote>'
  :author: Chris Dixon
  :topic_id: 728
- :url: https://netflixtechblog.com/notebook-innovation-591ee3221233?source=search_post---------5
  :title: 'Beyond Interactive: Notebook Innovation at Netflix'
  :content: '<p>By Michelle Ufford, M Pacer, Matthew Seal, and Kyle Kelley</p><p>Notebooks
    have rapidly grown in popularity among data scientists to become the de facto
    standard for quick prototyping and exploratory analysis. At Netflix, we’re pushing
    the boundaries even further, reimagining what a notebook can be, who can use it,
    and what they can do with it. And we’re making big investments to help make this
    vision a reality.</p><p>In this post, we’ll share our motivations and why we find
    Jupyter notebooks so compelling. We’ll also introduce components of our notebook
    infrastructure and explore some of the novel ways we’re using notebooks at Netflix.</p><p>If
    you’re short on time, we suggest jumping down to the Use Cases section.</p><h2>Motivations</h2><p>Data
    powers Netflix. It permeates our thoughts, informs our <a href="https://medium.com/netflix-techblog/its-all-a-bout-testing-the-netflix-experimentation-platform-4e1ca458c15">decisions</a>,
    and challenges our <a href="https://medium.com/netflix-techblog/selecting-the-best-artwork-for-videos-through-a-b-testing-f6155c4595f6">assumptions</a>.
    It fuels <a href="https://medium.com/netflix-techblog/a-b-testing-and-beyond-improving-the-netflix-streaming-experience-with-experimentation-and-data-5b0ae9295bdf">experimentation</a>
    and <a href="https://medium.com/netflix-techblog/growth-engineering-at-netflix-accelerating-innovation-90eb8e70ce59">innovation</a>
    at <a href="https://www.popularmechanics.com/technology/a20138/netflix-interview-wired-traffic-exceeds-internet-capacity/">unprecedented
    scale</a>. Data helps us discover <a href="https://medium.com/netflix-techblog/studio-production-data-science-646ee2cc21a1">fantastic
    content</a> and deliver <a href="https://medium.com/netflix-techblog/artwork-personalization-c589f074ad76">personalized
    experiences</a> for our 130 million members <a href="https://medium.com/netflix-techblog/using-machine-learning-to-improve-streaming-quality-at-netflix-9651263ef09f">around
    the world</a>.</p><p>Making this possible is no small feat; it requires extensive
    engineering and infrastructure support. Every day more than 1 trillion events
    are written into a streaming ingestion pipeline, which is processed and written
    to a 100PB cloud-native data warehouse. And every day, our users run more than
    150,000 jobs against this data, spanning everything from reporting and analysis
    to machine learning and recommendation algorithms. To support these use cases
    at such scale, we’ve built an industry-leading Data Platform which is flexible,
    powerful, and complex (by necessity). We’ve also built a rich ecosystem of complementary
    tools and services, such as <a href="https://medium.com/netflix-techblog/evolving-the-netflix-data-platform-with-genie-3-598021604dda">Genie</a>,
    a federated job execution service, and <a href="https://medium.com/netflix-techblog/metacat-making-big-data-discoverable-and-meaningful-at-netflix-56fb36a53520">Metacat</a>,
    a federated metastore. These tools simplify the complexity, making it possible
    to support a broader set of users across the company.</p><p><img src="https://cdn-images-1.medium.com/max/3122/1*Yzh8GbLOuY3-_rh2bMu9Bw.jpeg"
    alt=""></p><p>User diversity is exciting, but it comes at a cost: the Netflix
    Data Platform — and its ecosystem of tools and services — must scale to support
    additional use cases, languages, access patterns, and more. To better understand
    this problem, consider 3 common roles: analytics engineer, data engineer, and
    data scientist.</p><p><img src="https://cdn-images-1.medium.com/max/3234/1*NRoFl1l4lIVQAAvmBOKd4A.jpeg"
    alt="Example of how tooling &amp; language preferences may vary across roles"><em>Example
    of how tooling &amp; language preferences may vary across roles</em></p><p>Generally,
    each role relies on a different set of tools and languages. For example, a data
    engineer might create a new aggregate of a dataset containing trillions of streaming
    events — using Scala in IntelliJ. An analytics engineer might use that aggregate
    in a new report on global streaming quality — using SQL and Tableau. And that
    report might lead to a data scientist building a new streaming compression model
    — using R and RStudio. On the surface, these seem like disparate, albeit complementary,
    workflows. But if we delve deeper, we see that each of these workflows has multiple
    overlapping tasks:</p><p>*<em>data exploration — *</em>occurs early in a project;
    may include viewing sample data, running queries for statistical profiling and
    exploratory analysis, and visualizing data</p><p>*<em>data preparation *</em>—
    iterative task; may include cleaning, standardizing, transforming, denormalizing,
    and aggregating data; typically the most time-intensive task of a project</p><p>*<em>data
    validation *</em>— recurring task; may include viewing sample data, running queries
    for statistical profiling and aggregate analysis, and visualizing data; typically
    occurs as part of data exploration, data preparation, development, pre-deployment,
    and post-deployment phases</p><p><strong>productionalization</strong> — occurs
    late in a project; may include deploying code to production, backfilling datasets,
    training models, validating data, and scheduling workflows</p><p>To help our users
    scale, we want to make these tasks as effortless as possible. To help our platform
    scale, we want to minimize the number of tools we need to support. But how? No
    single tool could span all of these tasks; what’s more, a single task often requires
    multiple tools. When we add another layer of abstraction, however, a common pattern
    emerges across tools and languages: run code, explore data, present results.</p><p>As
    it happens, an open source project was designed to do precisely that: <a href="http://jupyter.org/">Project
    Jupyter</a>.</p><h2>Jupyter Notebooks</h2><p><img src="https://cdn-images-1.medium.com/max/2984/0*cgQX-JHRytjbeDNx"
    alt="Jupyter notebook rendered in nteract desktop featuring [Vega](https://vega.github.io/)
    and [Altair](https://altair-viz.github.io/)"><em>Jupyter notebook rendered in
    nteract desktop featuring <a href="https://vega.github.io/">Vega</a> and <a href="https://altair-viz.github.io/">Altair</a></em></p><p>Project
    Jupyter began in 2014 with a goal of creating a consistent set of open-source
    tools for scientific research, reproducible workflows, computational narratives,
    and data analytics. Those tools translated well to industry, and today Jupyter
    notebooks have become an essential part of the data scientist toolkit. To give
    you a sense of its impact, Jupyter was awarded the <a href="https://blog.jupyter.org/jupyter-receives-the-acm-software-system-award-d433b0dfe3a2">2017
    ACM Software Systems Award</a> — a prestigious honor it shares with Java, Unix,
    and the Web.</p><p>To understand why the Jupyter notebook is so compelling for
    us, consider the core functionality it provides:</p><ul><li><p>a messaging protocol
    for introspecting and executing code which is language agnostic</p></li><li><p>an
    editable file format for describing and capturing code, code output, and markdown
    notes</p></li><li><p>a web-based UI for interactively writing and running code
    as well as visualizing outputs</p></li></ul><p>The Jupyter protocol provides a
    standard messaging API to communicate with kernels that act as computational engines.
    The protocol enables a composable architecture that separates where content is
    written (the UI) and where code is executed (the kernel). By isolating the runtime
    from the interface, notebooks can span multiple languages while maintaining flexibility
    in how the execution environment is configured. If a kernel exists for a language
    that knows how to communicate using the Jupyter protocol, notebooks can run code
    by sending messages back and forth with that kernel.</p><p>Backing all this is
    a file format that stores both code and results together. This means results can
    be accessed later without needing to rerun the code. In addition, the notebook
    stores rich prose to give context to what’s happening within the notebook. This
    makes it an ideal format for communicating business context, documenting assumptions,
    annotating code, describing conclusions, and more.</p><h2>Use Cases</h2><p>Of
    our many use cases, the most common ways we’re using notebooks today are: data
    access, notebook templates, and scheduling notebooks.</p><h3><strong>Data Access</strong></h3><p>Notebooks
    were first introduced at Netflix to support data science workflows. As their adoption
    grew among data scientists, we saw an opportunity to scale our tooling efforts.
    We realized we could leverage the versatility and architecture of Jupyter notebooks
    and extend it for general data access. In Q3 2017 we began this work in earnest,
    elevating notebooks from a niche tool to a first-class citizen of the Netflix
    Data Platform.</p><p>From our users’ perspective, notebooks offer a convenient
    interface for iteratively running code, exploring output, and visualizing data
    — all from a single cloud-based development environment. We also maintain a Python
    library that consolidates access to platform APIs. This means users have programmatic
    access to virtually the entire platform from within a notebook. Because of this
    combination of versatility, power, and ease of use, we’ve seen rapid organic adoption
    for all user types across our entire platform.</p><p>Today, notebooks are the
    most popular tool for working with data at Netflix.</p><h3><strong>Notebook Templates</strong></h3><p>As
    we expanded platform support for notebooks, we began to introduce new capabilities
    to meet new use cases. From this work emerged parameterized notebooks. A parameterized
    notebook is exactly what it sounds like: a notebook which allows you to specify
    parameters in your code and accept input values at runtime. This provides an excellent
    mechanism for users to define notebooks as reusable templates.</p><p>Our users
    have found a surprising number of uses for these templates. Some of the most common
    ones are:</p><ul><li><p>*<em>Data Scientist: *</em>run an experiment with different
    coefficients and summarize the results</p></li><li><p><strong>Data Engineer:</strong>
    execute a collection of data quality audits as part of the deployment process</p></li><li><p><strong>Data
    Analyst:</strong> share prepared queries and visualizations to enable a stakeholder
    to explore more deeply than Tableau allows</p></li><li><p><strong>Software Engineer:</strong>
    email the results of a troubleshooting script each time there’s a failure</p></li></ul><h3><strong>Scheduling
    Notebooks</strong></h3><p>One of the more novel ways we’re leveraging notebooks
    is as a unifying layer for scheduling workflows.</p><p>Since each notebook can
    run against an arbitrary kernel, we can support any execution environment a user
    has defined. And because notebooks describe a linear flow of execution, broken
    up by cells, we can map failure to particular cells. This allows users to describe
    a short narrative of execution and visualizations that we can accurately report
    against when running at a later point in time.</p><p>This paradigm means we can
    use notebooks for interactive work and smoothly move to scheduling that work to
    run recurrently. For users, this is very convenient. Many users construct an entire
    workflow in a notebook, only to have to copy/paste it into separate files for
    scheduling when they’re ready to deploy it. By treating notebooks as a logical
    workflow, we can easily schedule it the same as any other workflow.</p><p>We can
    schedule other types of work through notebooks, too. When a Spark or Presto job
    executes from the scheduler, the source code is injected into a newly-created
    notebook and executed. That notebook then becomes an immutable historical record,
    containing all related artifacts — including source code, parameters, runtime
    config, execution logs, error messages, and so on. When troubleshooting failures,
    this offers a quick entry point for investigation, as all relevant information
    is colocated and the notebook can be launched for interactive debugging.</p><h2>Notebook
    Infrastructure</h2><p>Supporting these use cases at Netflix scale requires extensive
    supporting infrastructure. Let’s briefly introduce some of the projects we’ll
    be talking about.</p><p><a href="https://github.com/nteract">**nteract</a>** is
    a next-gen React-based UI for Jupyter notebooks. It provides a simple, intuitive
    interface and offers several improvements over the classic Jupyter UI, such as
    inline cell toolbars, drag and droppable cells, and a built-in data explorer.</p><p><a
    href="https://github.com/nteract/papermill">**Papermill</a>** is a library for
    parameterizing, executing, and analyzing Jupyter notebooks. With it, you can spawn
    multiple notebooks with different parameter sets and execute them concurrently.
    Papermill can also help collect and summarize metrics from a collection of notebooks.</p><p><a
    href="https://github.com/nteract/nteract/blob/master/applications/commuter/README.md">**Commuter</a>**
    is a lightweight, vertically-scalable service for viewing and sharing notebooks.
    It provides a Jupyter-compatible version of the contents API and makes it trivial
    to read notebooks stored locally or on Amazon S3. It also offers a directory explorer
    for finding and sharing notebooks.</p><p><a href="https://netflix.github.io/titus/">**Titus</a>**
    is a container management platform that provides scalable and reliable container
    execution and cloud-native integration with Amazon AWS. Titus was built internally
    at Netflix and is used in production to power Netflix streaming, recommendation,
    and content systems.</p><p>We explore this architecture in our follow-up blog
    post, <a href="https://medium.com/@NetflixTechBlog/scheduling-notebooks-348e6c14cfd6">Scheduling
    Notebooks at Netflix</a>. For the purposes of this post, we’ll just introduce
    three of its fundamental components: storage, compute, and interface.</p><p><img
    src="https://cdn-images-1.medium.com/max/3840/1*WOEEJizYnO8ibtU2l9jWbA.jpeg" alt="Notebook
    Infrastructure at Netflix"><em>Notebook Infrastructure at Netflix</em></p><h3><strong>Storage</strong></h3><p>The
    Netflix Data Platform relies on Amazon S3 and EFS for cloud storage, which notebooks
    treat as virtual filesystems. This means each user has a home directory on EFS,
    which contains a personal workspace for notebooks. This workspace is where we
    store any notebook created or uploaded by a user. This is also where all reading
    and writing activity occurs when a user launches a notebook interactively. We
    rely on a combination of [workspace + filename] to form the notebook’s <em>namespace</em>,
    e.g. /efs/users/kylek/notebooks/MySparkJob.ipynb. We use this namespace for viewing,
    sharing, and scheduling notebooks. This convention prevents collisions and makes
    it easy to identify both the user and the location of the notebook in the EFS
    volume.</p><p>We can rely on the workspace path to abstract away the complexity
    of cloud-based storage from users. For example, only the filename of a notebook
    is displayed in directory listings, e.g. MySparkJob.ipynb. This same file is accessible
    at ~/notebooks/MySparkJob.ipynb from a terminal.</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*pjjOIx1g7g4XoTxWBv0pIw.png"
    alt="Notebook storage vs. notebook access"><em>Notebook storage vs. notebook access</em></p><p>When
    the user schedules a notebook, the scheduler copies the user’s notebook from EFS
    to a common directory on S3. The notebook on S3 becomes the source of truth for
    the scheduler, or <em>source notebook</em>. Each time the scheduler runs a notebook,
    it instantiates a new notebook from the source notebook. This new notebook is
    what actually executes and becomes an immutable record of that execution, containing
    the code, output, and logs from each cell. We refer to this as the <em>output
    notebook</em>.</p><p>Collaboration is fundamental to how we work at Netflix. It
    came as no surprise then when users started sharing notebook URLs. As this practice
    grew, we ran into frequent problems with accidental overwrites caused by multiple
    people concurrently accessing the same notebook . Our users wanted a way to share
    their active notebook in a read-only state. This led to the creation of <a href="https://github.com/nteract/nteract/tree/master/applications/commuter">**Commuter</a>**.
    Behind the scenes, Commuter surfaces the Jupyter APIs for /files and /api/contents
    to list directories, view file contents, and access file metadata. This means
    users can safely view notebooks without affecting production jobs or live-running
    notebooks.</p><h3><strong>Compute</strong></h3><p>Managing compute resources is
    one of the most challenging parts of working with data. This is especially true
    at Netflix, where we employ a highly-scalable containerized architecture on AWS.
    All jobs on the Data Platform run on containers — including queries, pipelines,
    and notebooks. Naturally, we wanted to abstract away as much of this complexity
    as possible.</p><p>A container is provisioned when a user launches a notebook
    server. We provide reasonable defaults for container resources, which works for
    ~87.3% of execution patterns. When that’s not enough, users can request more resources
    using a simple interface.</p><p><img src="https://cdn-images-1.medium.com/max/2360/0*FUdkFk_m2tyeloJa"
    alt="Users can select as much or as little compute + memory as they need"><em>Users
    can select as much or as little compute + memory as they need</em></p><p>We also
    provide a unified execution environment with a prepared container image. The image
    has common libraries and an array of default kernels preinstalled. Not everything
    in the image is static — our kernels pull the most recent versions of Spark and
    the latest cluster configurations for our platform. This reduces the friction
    and setup time for new notebooks and generally keeps us to a single execution
    environment.</p><p>Under the hood we’re managing the orchestration and environments
    with <a href="https://medium.com/netflix-techblog/titus-the-netflix-container-management-platform-is-now-open-source-f868c9fb5436">Titus</a>,
    our Docker container management service. We further wrap that service by managing
    the user’s particular server configuration and image. The image also includes
    user security groups and roles, as well as common environment variables for identity
    within included libraries. This means our users can spend less time on infrastructure
    and more time on data.</p><h3><strong>Interface</strong></h3><p>Earlier we described
    our vision for notebooks to become the tool of choice for working with data. But
    this presents an interesting challenge: how can a single interface support all
    users? We don’t fully know the answer yet, but we have some ideas.</p><p>We know
    we want to lean into simplicity. This means an intuitive UI with a minimalistic
    aesthetic, and it also requires a thoughtful UX that makes it easy to do the hard
    things. This philosophy aligns well with the goals of <a href="https://github.com/nteract/nteract">**nteract</a>**,
    a React-based frontend for Jupyter notebooks. It emphasizes simplicity and <a
    href="https://components.nteract.io/">composability</a> as core design principles,
    which makes it an ideal building block for the work we want to do.</p><p>One of
    the most frequent complaints we heard from users is the lack of native data visualization
    across language boundaries, especially for non-Python languages. nteract’s <a
    href="https://blog.nteract.io/designing-the-nteract-data-explorer-f4476d53f897">Data
    Explorer</a> is a good example of how we can make the hard things simpler by providing
    a language-agnostic way to explore data quickly.</p><p>You can see Data Explorer
    in action in this <a href="https://mybinder.org/v2/gh/nteract/examples/master?urlpath=%2Fnteract%2Fedit%2Fpython%2Fhappiness.ipynb">sample
    notebook</a> on MyBinder. <em>(please note: it may take a minute to load)</em></p><p><img
    src="https://cdn-images-1.medium.com/max/5652/1*uW5qwTm4FQ3OauOWu_MCcA.gif" alt="Visualizing
    the World Happiness Report dataset with nteract’s Data Explorer"><em>Visualizing
    the World Happiness Report dataset with nteract’s Data Explorer</em></p><p>We’re
    also introducing native support for parametrization, which makes it easier to
    schedule notebooks and create reusable templates.</p><p><img src="https://cdn-images-1.medium.com/max/3838/1*UjwesaxwjH3d1glkP41J4w.gif"
    alt="Native support for parameterized notebooks in nteract"><em>Native support
    for parameterized notebooks in nteract</em></p><p>Although notebooks are already
    offering a lot of value at Netflix, we’ve just begun. We know we need to <a href="https://jobs.netflix.com/search?q=notebooks">make
    investments</a> in both the frontend and backend to improve the overall notebook
    experience. Our work over the next 12 months is focused on improving reliability,
    visibility, and collaboration. Context is paramount for users, which is why we’re
    increasing visibility into cluster status, kernel state, job history, and more.
    We’re also working on automatic version control, native in-app scheduling, better
    support for visualizing Spark DataFrames, and greater stability for our Scala
    kernel. We’ll go into more detail on this work in a future blog post.</p><h2>Open
    Source Projects</h2><p>Netflix has long been a proponent of open source. We value
    the energy, open standards, and exchange of ideas that emerge from open source
    collaborations. Many of the applications we developed for the Netflix Data Platform
    have already been open sourced through <a href="https://netflix.github.io/">Netflix
    OSS</a>. We are also intentional about not creating one-off solutions or succumbing
    to “Not Invented Here” mentality. Whenever possible, we leverage and contribute
    to existing open source projects, such as <a href="https://github.com/apache/spark">Spark</a>,
    <a href="https://github.com/jupyter">Jupyter</a>, and <a href="https://github.com/pandas-dev/pandas">pandas</a>.</p><p>The
    infrastructure we’ve described relies heavily on the Project Jupyter ecosystem,
    but there are some places where we diverge. Most notably, we have chosen <a href="https://github.com/nteract">**nteract</a>**
    as the notebook UI for Netflix. We made this decision for many reasons, including
    alignment with our technology stack and design philosophies. As we push the limits
    of what a notebook can do, we will likely create new tools, libraries, and services.
    These projects will also be open sourced as part of the nteract ecosystem.</p><p>We
    recognize that what makes sense for Netflix does not necessarily make sense for
    everyone. We have designed these projects with modularity in mind. This makes
    it possible to pick and choose only the components that make sense for your environment,
    e.g. Papermill, without requiring a commitment to the entire ecosystem.</p><h2>What’s
    Next</h2><p>As a platform team, our responsibility is to enable Netflixers to
    do amazing things with data. Notebooks are already having a dramatic impact at
    Netflix. With the significant investments we’re making in this space, we’re excited
    to see this impact grow. If you’d like to be a part of it, check out <a href="https://jobs.netflix.com/search?q=notebooks">our
    job openings</a>.</p><p>Phew! Thanks for sticking with us through this long post.
    We’ve just scratched the surface of what we’re doing with notebooks. This post
    is part one in a series on notebooks at Netflix we’ll be releasing over the coming
    weeks. You can follow us on Medium for more from Netflix and check out the currently
    released articles below:</p><ul><li><p>Part I: <a href="https://medium.com/netflix-techblog/notebook-innovation-591ee3221233">Notebook
    Innovation</a> (this post)</p></li><li><p>Part II: <a href="https://medium.com/@NetflixTechBlog/scheduling-notebooks-348e6c14cfd6">Scheduling
    Notebooks</a></p></li></ul><p>We’re thrilled to sponsor this year’s <a href="https://conferences.oreilly.com/jupyter/jup-ny">JupyterCon</a>.
    If you’re attending, check out one of the 5 talks by our engineers, or swing by
    our booth to talk about Jupyter, nteract, or data with us.</p><ul><li><p>8/22
    1:30 PM — <a href="https://conferences.oreilly.com/jupyter/jup-ny/public/schedule/detail/68413">How
    to Build on top of Jupyter’s Protocols</a>, <em>Kyle Kelley</em></p></li><li><p>8/23
    1:50 PM — <a href="https://conferences.oreilly.com/jupyter/jup-ny/public/schedule/detail/68348">Scheduled
    Notebooks: Manageable and traceable code execution</a>, <em>Matthew Seal</em></p></li><li><p>8/23
    2:40 PM — <a href="https://conferences.oreilly.com/jupyter/jup-ny/public/schedule/detail/71601">Notebooks
    @ Netflix: From Analytics to Engineering</a>, <em>Michelle Ufford, Kyle Kelley</em></p></li><li><p>8/23
    5:00 PM — <a href="https://conferences.oreilly.com/jupyter/jup-ny/public/schedule/detail/71220">Making
    beautiful objects with Jupyter</a>, <em>M Pacer</em></p></li><li><p>8/24 2:40
    PM — <a href="https://conferences.oreilly.com/jupyter/jup-ny/public/schedule/detail/71220">Jupyter’s
    configuration system</a>, <em>M Pacer</em> et. al.</p></li><li><p>8/25 9AM — 5PM
    <a href="https://blog.jupyter.org/jupytercon-2018-registration-open-3b52abba9cce#a707">JupyterCon
    Community Sprint Day</a></p></li></ul><p>There are more ways to learn from Netflix
    Data and we’re happy to share:</p><ul><li><p><a href="http://twitter.com/NetflixData">@NetflixData</a>
    on Twitter</p></li><li><p><a href="https://www.youtube.com/channel/UC00QATOrSH4K2uOljTnnaKw/featured">Netflix
    Data</a> talks on YouTube</p></li><li><p><a href="https://research.netflix.com/">Netflix
    Research</a> website</p></li></ul><p>You can also stay up to date with nteract
    via their <a href="http://bit.ly/nteract-monthly">mailing list</a> and <a href="https://blog.nteract.io/">blog</a>!</p>'
  :author: Netflix TechBlog
  :topic_id: 728
- :url: https://digitalculturist.com/stop-saying-technology-is-causing-social-isolation-1e004de63a5e?source=search_post---------6
  :title: Stop Saying Technology is Causing Social Isolation
  :content: '<p>Stop Saying Technology is Causing Social Isolation</p><p>A group of
    friends checking their smartphones while hanging out. Almost everyone on the subway
    with their eyes fixed on their gadget’s screens. A couple laying together in bed
    with their iPhones in their hands. People with their devices up in the air taking
    pictures of a concert. And I could go on. Technology, and especially smartphones,
    is ruining society, making us disconnected from others, interacting with our devices
    instead of with each other.</p><p>Except, fuck that.</p><p><img src="https://cdn-images-1.medium.com/max/2136/1*oRn8iwuHxO2wvj9tYIXU3Q.jpeg"
    alt="Illustration by [Rosangela Ludovico](http://hugtherobots.tumblr.com/post/69627090387/i-know-its-trendy-to-fight-the-system-and-cry)"><em>Illustration
    by <a href="http://hugtherobots.tumblr.com/post/69627090387/i-know-its-trendy-to-fight-the-system-and-cry">Rosangela
    Ludovico</a></em></p><p>People like to criticize current society. Not necessarily
    the current society relative to us, but the contemporary society of the <a href="https://en.wikipedia.org/wiki/Golden_age_%28metaphor%29">time</a>
    they live in. It’s just so cool to romanticize the past even if <a href="https://www.psychologytoday.com/blog/turning-straw-gold/201308/romanticizing-the-past-makes-us-feel-bad-about-the-present">it
    makes us feel bad about the present</a>. Past times were always better. And in
    this age of information and technology, in which the smartphone is so ubiquitous,
    it’s only obvious to blame them for some of society’s problems. Of course, it’s
    perfectly reasonable to stop and reflect on the use we give to technology and
    to criticize the bad behaviors associated. But I believe that accusing technology
    (and, again, especially smartphones) of ruining social interaction and even all
    kinds of experiences is, to say the least, quite wrong and misguided. Some people
    would even qualify that as pretentious, but I’ll refrain from that.</p><p>If you
    have used the internet in the last years (and I suspect you have), you have probably
    seen a picture on your Facebook feed or on your Tumblr dashboard or nearly everywhere
    pointing out, with a sense of superiority, how people are slaves of technology
    nowadays, always using their electronic devices in public. I’m talking about illustrations
    like <a href="http://azurea.tumblr.com/post/104686647920">these</a>. Or comics
    like <a href="http://zenpencils.com/comic/129-marc-maron-the-social-media-generation/">these</a>.
    Or short films like <a href="https://www.youtube.com/watch?v=OINa46HeWg8">these</a>.
    Or articles like <a href="http://www.popsugar.com/tech/Experiences-Better-Without-Smartphones-37636606">these</a>
    or <a href="http://www.villagevoice.com/music/six-reasons-why-your-phone-is-probably-ruining-your-concert-experience-and-everyone-elses-6638538">these</a>.
    Or photographic projects like <a href="http://www.ericpickersgill.com/Removed">these</a>.
    Again, I could go on. The world wide web is filled with all kinds of expressive
    works related to this issue, probably because it’s something people care about.
    But I feel that most of that content treats it using the same premise: smartphones
    are ruining our lifes (at least to some extent).</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*0aGhIu5NxNgfXOFptwN4rw.jpeg"
    alt="Illustration by [Jean Jullien](http://www.jeanjullien.com/). The fun people
    didn’t go away — they’re here and everywhere"><em>Illustration by <a href="http://www.jeanjullien.com/">Jean
    Jullien</a>. The fun people didn’t go away — they’re here and everywhere</em></p><p>Everytime
    I see content like that, I feel the need to express my profound disagreement,
    for which I usually resort to Twitter, always ending up wanting to say more than
    I could, so I decided to write this piece. Of course, this expresses my views
    (and, I hope, the views of many others) just like those authors whose works I’m
    commenting on, so you may disagree with me and find that they are right and I’m
    not.</p><p>My main premise is that I don’t think smartphones are isolating us,
    destroying our social lives or ruining interactions. I see smartphones as <a href="http://www.theverge.com/2015/10/11/9493425/technology-isnt-a-tool-its-an-instrument">instruments</a>
    for communication. Instruments that enable interaction on ways that just weren’t
    possible before, connecting us with people all around the world, via Twitter,
    instant messaging or other services. Some may say that if you want to interact
    with people, you should interact with the ones around you, and that is probably
    true on certain occasions. But, on other occasions, I’m just not able to comprehend
    why should we be forced to interact with those physically close to us instead
    of with the people that we <em>really</em> want to interact with.</p><p>Is it
    so bad to prefer talking with a long-distance partner using a smartphone than
    with someone who does not interest me but happens to be next to me? To prefer
    reading how the people you’ve followed by years on Twitter are doing instead of
    making smalltalk with that friend of a friend sitting across the subway car? Maybe
    you think that yes, it is bad, that people should always prioritize physical interaction
    to digital one. I disagree. Except for obvious occasions (a work meeting, an actual
    conversation that is taking place between you and someone, etc.), I think people
    should be able to interact with whomever they please without being judged by people
    for using a smartphone to do so.</p><p>It all boils down to letting people connect
    freely using the medium they feel the most comfortable with at the moment. Maybe
    that acquaintance of yours hasn’t gone talk to you because she has had a bad day
    and just wants to relax checking her Instagram feed or listening to some music.
    Maybe your friend has taken his smartphone out of his pocket because he has gotten
    a message that he needs to reply now. Or maybe it’s just that he feels a bit uncomfortable
    and is using his phone to try and avoid the awkwardness of the moment because
    he has social anxiety and you should respect that. And yes, maybe, maybe some
    people are using their smartphones while they objectively shouldn’t without any
    possible excuses and they’re jerks (or they just made a mistake and didn’t realize
    taking their phone out would make someone upset), but I think it’s really unfair
    to assume everyone or nearly everyone who uses a smartphone in public does that.</p><p><img
    src="https://cdn-images-1.medium.com/max/2038/1*eUoMlh7kn9M24uRgVGhecg.png" alt="Photo
    by [John Blanding](https://www.bostonglobe.com/staff/blanding) tweeted by [Wayne
    Dahlberg](https://twitter.com/waynedahlberg/status/647631533046562816/photo/1?ref_src=twsrc%5Etfw).
    It’s trying to convey the idea that this woman is enjoying the experience more
    than the other people taking photos or recording. I’m not sure those people are
    really enjoying it less because of their smartphones"><em>Photo by <a href="https://www.bostonglobe.com/staff/blanding">John
    Blanding</a> tweeted by <a href="https://twitter.com/waynedahlberg/status/647631533046562816/photo/1?ref_src=twsrc%5Etfw">Wayne
    Dahlberg</a>. It’s trying to convey the idea that this woman is enjoying the experience
    more than the other people taking photos or recording. I’m not sure those people
    are really enjoying it less because of their smartphones</em></p><p>Part of the
    commentaries I’ve seen criticizing this whole issue also touch on social media,
    since it is so integrated with our usual smartphone usage. For example, I see
    lots of people complaining about people who take pictures of the food they order
    at restaurants for posting them on Instagram or wherever. I don’t get that. Is
    it wrong to create a permanent memento of an otherwise temporary experience, to
    capture in a photo the work of the people back in the kitchen who made an effort
    to make the food look attractive? To me, those complaints allude to a lack of
    understanding of how modern social media works.</p><p>I think Tumblr user zmizet
    expresses this very accurately in their <a href="http://zmizet.tumblr.com/post/104849285847/poopjokesanonymous-barbieprivilege">comments</a>
    on the Jean Jullien illustrations that I’ve used here. On that exact topic of
    taking photos of food, zmizet expressed the following:</p><blockquote><p>I’m happy
    <strong>seeing my friends take photos of their food</strong>. I like taking photos
    of my food. Because there is a chef in the back of the kitchen who works hard
    to plate things beautifully and in any other situation, people dive in immediately
    and ruin that image. We take photos to preserve that image and who the fuck knows,
    if I was the chef I would be digging through instagram hoping to see my plate
    on there. We’re <strong>celebrating someones hard work</strong>, work that is
    <strong>generally temporary</strong>.</p></blockquote><p>And I agree with that.
    zmizet concludes:</p><blockquote><p>Technology isn’t bad. You’re just upset with
    yourselves for having a lack of self-control. You hate that people connect through
    technology. And maybe, you just don’t like seeing people love themselves, enjoy
    life, and feel joy. That’s your problem, not technology’s.</p></blockquote><p>Social
    media itself is also not bad. It doesn’t make us more socially isolated. Quite
    the contrary, it expands our social network, as shown in <a href="http://www.pewinternet.org/2009/11/04/social-isolation-and-new-technology/">this
    report</a> by Pew Research Center which concludes:</p><blockquote><p>Compared
    to those who do not use the internet, most people who use the internet and use
    a social networking service, such as Facebook, MySpace, or LinkedIn, have social
    networks that are about 20% more diverse.</p></blockquote><p>It dates back to
    2009, when social media wasn’t as big as it is now, but I firmly believe it still
    stands correct today. I’d also like to point out this key paragraph:</p><blockquote><p>Newer
    information and communication technologies provide new settings and a means of
    communication that independently contribute to the diversity of people’s social
    networks.</p></blockquote><p>Social media, and smartphones for that matter, only
    contributes to make our social experiences richer by connecting us with people
    in new ways. I’m sure many of you have met lots of interesting people. I sure
    have. Thanks to social media, I’ve been able to meet people that are now close
    friends of mine. And when I’m out, I like to open Twitter and check how they are,
    what they are doing, if I have something to say that may interest them. Heck,
    I even met my girlfriend on Twitter years ago. And I’m absolutely certain that
    my experience is not an isolated one, as the research above shows.</p><p><img
    src="https://cdn-images-1.medium.com/max/2000/1*72zfuOPxWKmNihQAtofSqA.jpeg" alt="Vignette
    of a comic by [Gavin Aung Than](http://zenpencils.com/comic/129-marc-maron-the-social-media-generation/)"><em>Vignette
    of a comic by <a href="http://zenpencils.com/comic/129-marc-maron-the-social-media-generation/">Gavin
    Aung Than</a></em></p><p><img src="https://cdn-images-1.medium.com/max/2000/1*P6X7hoA9fp6BYE6FolR3GQ.jpeg"
    alt="Popular image of nearly everyone on the train reading the newspaper instead
    of talking with each other decades ago"><em>Popular image of nearly everyone on
    the train reading the newspaper instead of talking with each other decades ago</em></p><p>Other
    frequent topic appears to be one I’ve already mentioned. People using their smartphones
    on the subway, the bus or the train. This is shown in the illustration used at
    the beginning of this writing or in the comic I referenced above. This is probably
    the one I get the least. What else could people do? What would they do if smartphones
    didn’t exist? Talking to each other? Let’s not fool ourselves. People in general
    do not like to interact with strangers in these contexts. They didn’t when smartphones
    were far from existing; they just used another object instead, like a newspaper.
    In response to the vignette next to this paragraph, Tumblr user bogleech <a href="http://bogleech.tumblr.com/post/68941324116/an-angry-tirade-about-one-comic">commented</a>
    the following:</p><blockquote><p>OH MAN look at those ignorant, pathetic people
    of various ages, sexes and ethnic groups all doing** internet shit** on their
    phones while they ride on a subway! HOLY SHIT THEY’RE ALL DOING IT! EVEN THE GUY
    IN THE <strong>TURBAN</strong> FROM WHATEVER THE HELL VAGUE COUNTRY HE’S SUPPOSED
    TO BE FROM THAT HAS TURBANS!WHY ARE THEY MESSAGING ESTABLISHED FRIENDS AND FAMILY
    ON A PHOENEZ WHEN THEY COULD BE INTERACTING WITH COMPLETE AND UTTER STRANGERS
    ON A GROSS FUCKING SUBWAY CARHOW DARE THEY HAVE PERSONAL OUTLETS AND PRIVATE SPACE
    AND SHIT</p></blockquote><p>The person who wrote that was clearly really passionate
    about this topic. And well, I think that, although violently, they deliver the
    message I’m trying to convey here.</p><p>They also went on to say:</p><blockquote><p>DIGITAL
    TECHNOLOGY OVER JUST THE PAST DECADE HAS CONNECTED AND EDUCATED MORE HUMAN MINDS
    THAN PROBABLY THE ENTIRE SUM OF OUR PLANET’S HISTORYIT’S ALSO A MIRACULOUS FIRST-WORLD
    PRIVILEGE THAT ALLOWS YOU TO MAKE FRIENDS, SHARE YOUR IDEAS, LEARN NEW THINGS,
    HEAL EMOTIONAL WOUNDS THROUGH SOCIAL INTERACTION, FIND ESCAPE FROM ABUSIVE SITUATIONS,
    FIND NEW LIVING SITUATIONS, APPLY FOR JOBS, CREATE YOUR OWN PERSONAL OUTLETS AND
    GENERALLY PURSUE HAPPINESS AT THE TOUCH OF A DAMN BUTTON</p></blockquote><p>You
    don’t have to take their word for it. There are studies that back up all of that
    like <a href="http://www.technologyreview.com/view/530566/the-impact-of-the-internet-on-society-a-global-perspective/">this
    one</a> or <a href="http://www.internetsociety.org/globalinternetreport/assets/download/IS_web.pdf">this
    one</a>.</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*hJQbKAv9l_aB5UxNBbh5Qw.jpeg"
    alt="Illustration by [Jean Jullien](http://www.jeanjullien.com/). Is it so bad
    to have the ability to not be alone using our phones?"><em>Illustration by <a
    href="http://www.jeanjullien.com/">Jean Jullien</a>. Is it so bad to have the
    ability to not be alone using our phones?</em></p><p><strong>In conclusion</strong>,
    I think we need to stop thinking technology is ruining everything, making us a
    slave to it, mindlessly using our smartphones all the time. It is not. It is enriching
    our lives, connecting us to the people that matter the most to us regardless of
    how far away they are, connecting us to all kinds of people whom we wouldn’t have
    met otherwise. So, stop feeling superior for making fun of other people because
    they’re using their smartphones, stop pretending our lives and society would be
    better without them, stop blaming technology for natural human behaviors. If you
    see an image like the ones I referenced here, the ones trying to show how we are
    <a href="http://kamikazeruler.tumblr.com/post/104820349487/azurea-by-jean-jullien-visual-representation">“</a>letting
    technology ruin social interactions and pleasant experiences”, stop and reflect
    on <em>why</em> people are actually using their electronic devices. Furthermore,
    stop romanticizing the past, believing life was better without all of this ubiquitous
    technology like in some form of “neo-ludism”. Consumer technology is good. It
    enables us to connect in amazing ways as humans. It is not replacing real interaction.
    It is augmenting it. <strong>Embrace it</strong>.</p><p><em>All of the rights
    of the images used in this article belong not to me but to their original authors,
    referenced and linked below each image.</em></p>'
  :author: Digital Culturist
  :topic_id: 728
- :url: https://onezero.medium.com/the-technology-that-will-define-2019-48c041e98532?source=search_post---------7
  :title: The Technology That Will Define 2019
  :content: '<p>The Technology That Will Define 2019</p><h3><em>A major iPhone shakeup,
    5G, and even more bitcoin are on the horizon</em></h3><p><img src="https://cdn-images-1.medium.com/max/7470/1*xbr8zwOAJ8fBpgYZSyv_4w.jpeg"
    alt="Credit: Malte Mueller/Getty"><em>Credit: Malte Mueller/Getty</em></p><p>A
    year ago, I picked <a href="https://medium.com/swlh/7-technologies-to-watch-in-2018-e7e365ebd00">seven
    technologies</a> that would play significant roles in 2018. Some of my predictions
    were correct, and some of them reappear on this list — 5G hasn’t quite happened
    yet, but we’re getting closer.</p><p>As George Saville, the 17th-century English
    statesman and essayist, once wrote, “The best qualification of a prophet is to
    have a good memory.” It’s a fancy way of saying the past is prologue, and no vision
    for the near-future is possible without analyzing past trends. That’s what I’ve
    done to concoct these informed guesses about the state of tech in 2019.</p><p>Of
    course, there are bound to be surprises and off-base prognostications. Don’t sue
    me if things go a bit differently than expected.</p><h2><strong>1. Cryptocurrency</strong></h2><p>Bitcoin
    opened 2018 at almost $17,000 in value and exited at under $4,000. This does not
    mean the end of it or other emerging cryptocurrencies.</p><p>The year 2018 taught
    us that the broad concept behind cryptocurrency — the blockchain — could be useful
    <a href="https://medium.com/s/thenewnew/the-blockchain-could-save-legalized-weed-stop-rolling-your-eyes-53b47125c761">elsewhere</a>.
    Expect token experiments in <a href="https://news.bitcoin.com/powerful-cryptocurrency-firms-on-the-road-towards-becoming-banks/">banking</a>,
    <a href="https://www.forbes.com/sites/yoavvilner/2018/09/29/9-blockchain-and-cryptocurrency-companies-all-set-for-2019/#60847c431400">business</a>,
    and <a href="https://tokenfoundry.com/projects/civil">media</a> to expand in 2019.
    Many will fail as token entrepreneurs struggle to connect offerings to <a href="https://www.latimes.com/business/la-fi-bitcoin-bubble-20180629-story.html">real-world
    value</a>. But <a href="https://www.technologyreview.com/s/610836/how-secure-is-blockchain-really/">immutable
    ledgers</a> are attractive to an increasingly security-conscious world, and they
    will become the foundation of innumerable new ways of buying, selling, and accounting.</p><h2><strong>2.
    “Screen Time” Services</strong></h2><p>We loved social media, we overused it,
    and now we’re finding that it probably <a href="https://www.makeuseof.com/tag/negative-effects-social-media/">isn’t
    that good for us</a>. In addition, whatever trust we once had in the world’s most
    popular social platform, Facebook, <a href="https://www.adweek.com/digital/facebooks-terrible-horrible-no-good-very-bad-year/">all
    but vanished in 2018</a>. Thus, 2019 should bring a reconsideration of our obsession
    with sharing and those dopamine-producing likes and hearts.</p><p>Instead of measuring
    followers, we’ll start comparing <a href="https://medium.com/@LanceUlanoff/apple-ios-12-is-a-toolbox-full-of-iphone-breaks-613630e7c1f">screen
    times</a>. Expect <a href="https://www.telegraph.co.uk/technology/2018/03/01/app-cures-digital-addiction-rewarding-users-avoiding-phone/">more
    apps</a>, <a href="https://www.youtube.com/watch?v=NuoUs7LmBDY">hardware</a>,
    and <a href="https://paradigmmalibu.com/teen-social-media-addiction-treatment/">IRL</a>
    services to reward us for the time we don’t spend online. Apple’s iOS Screen Time,
    Android’s Dashboard, and third-party apps like <a href="https://www.hold.app/">Hold</a>
    are just the tip of the iceberg.</p><h2><strong>3. Cyberwarfare</strong></h2><p>World
    War III is upon us, but instead of boots on the ground, it’s all about binaries
    in the ether.</p><p>After Russia essentially — albeit secretly — declared war
    on the United States by undermining the <a href="https://www.nytimes.com/2018/02/16/us/politics/russia-mueller-election.html">2016
    presidential election</a>, it and <a href="https://www.usatoday.com/story/opinion/2018/07/31/chinas-hacking-and-influence-goes-unnoticed-while-we-focus-russia-column/860289002/">other
    insurgents</a> have turned their attentions to manipulating hearts, minds, <a
    href="https://www.nytimes.com/2018/12/21/us/politics/russia-midterm-election-influence-coates.html">elections</a>,
    and even <a href="https://en.wikipedia.org/wiki/Russian_interference_in_the_2016_Brexit_referendum">Brexit</a>.
    The quietest worldwide conflagration will continue this year.</p><p>Educating
    the populace on how they’re being manipulated every single day through technology
    and social media will become a critical priority in 2019. P.W. Singer and Emerson
    T. Brooking’s <a href="https://www.amazon.com/LikeWar-Weaponization-P-W-Singer/dp/1328695743">*LikeWar</a>*
    should become required reading in high schools and colleges.</p><h2><strong>4.
    Regulation</strong></h2><p>The year 2018 was a low point for privacy, with revelations
    that the most popular social media platform on the planet <a href="https://www.nytimes.com/interactive/2018/06/03/technology/facebook-device-partners-users-friends-data.html">all
    but handed the keys to our personal profiles</a> to a range of partners. Americans,
    following the <a href="https://www.zdnet.com/article/gdpr-an-executive-guide-to-what-you-need-to-know/">General
    Data Protection Regulation</a> in Europe, will demand change.</p><p>In 2019, we’ll
    see movement on the collection of bills from <a href="https://www.meritalk.com/articles/house-members-spar-over-data-privacy-bills-path-forward-remains-murky/">the
    U.S. House and Senate</a> that are aimed at officially regulating the tech industry.
    They could eventually be combined into one overarching Personal Data Privacy Act
    of 2019.</p><p>This kind of policy will have broad, bipartisan support and perhaps
    <a href="https://bakertilly.com/insights/us-federal-data-privacy-law-gains-support-of-tech-giants/">grudging
    support in the tech sector</a>. Assuming the legislation doesn’t overreach, the
    big question will be if the regulation-averse Trump White House will sign. If
    and when that happens, expect GDPR-level changes in how companies like Google,
    Facebook, and Amazon do business. You’ll like some of it — it will be harder for
    companies to use your data without explicit consent, for example — but regulations
    may also slow innovation.</p><h2><strong>5. Electric Self-Driving Cars</strong></h2><p>Most
    states now have some sort of <a href="http://www.ncsl.org/research/transportation/autonomous-vehicles-self-driving-vehicles-enacted-legislation.aspx">self-driving
    automotive legislation</a> on the books, and many new cars have enough built-in
    intelligence to do typical driving tasks. Still, the spread of autonomous driving
    was sporadic at best in 2018. This year could be a huge turning point.</p><p>States
    that have yet to get on board with the technology are being spurred by new <a
    href="http://www.ncsl.org/research/transportation/autonomous-vehicles-self-driving-vehicles-enacted-legislation.aspx">federal
    guidelines</a> enacted in September. In addition, Tesla’s Model 3, the <a href="https://cleantechnica.com/2018/09/09/tesla-model-3-becomes-1-best-selling-car-in-the-us/">bestselling
    sedan</a> in the United States (by revenue, not total units sold), already has
    some of the most powerful <a href="https://www.tesla.com/support/software-v9">autonomous
    driving technology</a> on the road.</p><p>Expect new, all-electric Model 3 competitors
    and tests with self-driving-only lanes on some highways.</p><h2><strong>6. Apple’s
    Mobile Lead Shrinks</strong></h2><p>Every time I run <a href="https://www.geekbench.com/">Geekbench</a>
    on the latest flagship phones from Apple, Samsung, Motorola, LG, and others, the
    iPhone comes out on top. Apple’s custom silicon isn’t just marginally more powerful
    than the Qualcomm CPUs most Android handsets are running — it’s leaps and bounds
    better.</p><p>That may change in 2019, as <a href="https://www.pcgamer.com/intel-says-10nm-cannon-lake-shipments-still-on-track-as-it-deals-with-14nm-cpu-shortage/">Intel</a>
    and <a href="https://www.androidcentral.com/qualcomm-snapdragon-855">Qualcomm</a>
    promise new, A.I.-infused mobile CPUs that could level the playing field. Obviously,
    handset performance is not solely defined by numbers in a benchmark. Apple’s A12
    Bionic wins because it outperforms competitors on core tasks like video editing,
    gaming, and augmented reality. How Qualcomm and Intel’s next-gen mobile processors
    handle those tasks will define our mobile computing lives in 2019.</p><h2><strong>7.
    5G</strong></h2><p>5G got off to a slower start than I expected in 2018, but the
    arrival of 5G-ready mobile CPUs and an <a href="https://www.rcrwireless.com/20181002/carriers/verizon-will-be-extremely-aggressive-with-5g-roll-out">improved
    infrastructure</a> could mean a rapid rollout in 2019 — at least on the Android
    side. Rumors that Apple may wait to support the ultrafast mobile technology <a
    href="https://www.macrumors.com/2018/12/03/apple-to-delay-5g-iphone-support-until-2020/">until
    2020</a> could put a damper on 5G enthusiasm.</p><p>Unfortunately, Apple’s rumored
    decision might be a canny one, as it’s possible that the mismatch between <a href="https://www.t3.com/news/best-5g-phones">5G-ready
    handsets</a> and available infrastructure may persist throughout 2019, pushing
    the Year of 5G into 2020 and beyond. In the meantime, don’t be fooled by <a href="https://mashable.com/article/att-will-add-fake-5g-labels-to-android-phones/#BiUiMA3aMaq7">tricky
    branding</a> from the likes of AT&amp;T.</p><h2><strong>8. Robots</strong></h2><p>Boston
    Dynamics’ “<a href="https://www.youtube.com/watch?v=hSjKoEva5bg">parkour bot</a>”
    has me believing that 2019 will be the year of C-3PO — or something like it. Agile,
    humanoid robots with <a href="https://www.forbes.com/sites/zarastone/2017/11/07/everything-you-need-to-know-about-sophia-the-worlds-first-robot-citizen/#4686ee5746fa">uncanny
    valley–busting, human-like faces</a> will appear in more and more videos and perhaps
    a few pilot programs <a href="http://fortune.com/2018/06/27/pepper-the-robot-hsbc-job/">in
    offices</a> and <a href="https://www.digitaltrends.com/cool-tech/robots-to-make-robots-at-one-of-the-worlds-most-advanced-facilities/">factories</a>.
    Somewhere in the mix we’ll see next-gen sexbots. They’ll be just as <a href="https://www.forbes.com/sites/brucelee/2018/06/05/in-case-you-are-wondering-sex-with-robots-may-not-be-healthy/#4a886d631f6b">realistic
    and gross</a> as you imagined. It’ll all be a far cry from Will Smith’s <em>I,
    Robot</em>, but it should also be the beginning of a reassociation of the word
    “android” with robots instead of phones.</p><h2><strong>9. Facial Recognition
    and Manipulation</strong></h2><p>Conversations around facial recognition will
    become more urgent in 2019, as the technology becomes more <a href="https://qz.com/1493149/taylor-swift-used-facial-recognition-to-track-her-stalkers-at-a-concert/">widespread</a>
    and <a href="https://www.washingtonpost.com/technology/2018/12/30/fake-porn-videos-are-being-weaponized-harass-humiliate-women-everybody-is-potential-target/?utm_term=.47f4c7676ad1">open
    to abuse</a>. Programmers will start to scrub <a href="https://www.theverge.com/2018/2/11/17001218/facial-recognition-software-accuracy-technology-mit-white-men-black-women-error">inherent
    biases out of systems</a>, improving the underlying technology; companies like
    Amazon will continue to <a href="https://www.bloomberg.com/news/articles/2018-10-23/amazon-pitches-facial-recognition-tools-to-monitor-immigrants">pitch</a>
    facial recognition to the government; and with the emergence of <a href="https://www.youtube.com/watch?v=cQ54GDm1eL0">deepfakes</a>,
    all of us will struggle mightily with the idea that imagery can never again be
    trusted.</p><h2><strong>10. AR, Not VR</strong></h2><p>Virtual reality <a href="https://www.oculus.com/blog/introducing-oculus-quest-our-first-6dof-all-in-one-vr-system-launching-spring-2019/">isn’t
    here to stay</a>. But augmented reality will break out in 2019, as the majority
    of flagship phones already support it.</p><p>Meanwhile, it’ll be a make-or-break
    year for the underwhelming <a href="https://www.gamesradar.com/i-still-cant-see-the-future-for-ar-gaming-after-wearing-the-dollar2295-magic-leap-headset/">Magic
    Leap headset</a>, which might be doomed if Apple finally shows off the AR wearable
    <a href="https://www.engineering.com/ARVR/ArticleID/17593/Apples-Quietly-Making-an-Augmented-Reality-Headset.aspx">everyone
    believes</a> it’s been working on for years.</p><p>Do not expect Microsoft to
    introduce a HoloLens for everyone in 2019. However, the mixed reality experiences
    on third-party <a href="https://www.microsoft.com/en-us/store/collections/vrandmixedrealityheadsets">mixed
    reality headsets</a> will vastly improve and add more tools for business and enterprise
    users, including <a href="https://www.maquette.ms/">Maquette</a>, which helps
    people build prototype applications in real time.</p><h2><strong>Lightning Round</strong></h2><ul><li><p>Apple
    put USB-C on the new iPad Pro line last year. Expect it to ditch the Lightning
    port and go with USB-C across its <a href="https://medium.com/@LanceUlanoff/the-apple-ipad-pro-12-9-is-a-glorious-creation-machine-6bc1b918e5d9">iPhone
    lineup</a> in 2019.</p></li><li><p>The proliferation of OTT streaming services
    will continue in 2019 with more à la carte choices and must-see shows on subscription
    platforms from <a href="https://www.polygon.com/2018/10/4/17924674/star-wars-tv-show-the-mandalorian-jon-favreau">Disney</a>,
    <a href="https://variety.com/2018/biz/news/warnermedia-streaming-platform-movies-three-tiers-1203051216/">WarnerMedia</a>,
    and <a href="https://www.adweek.com/tv-video/ott-overload-all-the-media-companies-preparing-to-launch-new-streaming-services-in-2019/">everybody
    in between</a>. It’ll be a confusing year, but that won’t stop more consumers
    from cutting the cable cord and leaving only broadband internet intact.</p></li><li><p>One
    academic’s insanely <a href="https://www.scientificamerican.com/article/first-crispr-babies-6-questions-that-remain/">unethical
    CRISPR experiment</a> is probably just the start. The proverbial double helix
    is out of the bottle, and 2019 will be filled with more gene-editing revelations.</p></li><li><p>As
    <a href="https://www.npr.org/sections/goatsandsoda/2018/06/28/623972937/china-has-refused-to-recycle-the-wests-plastics-what-now">China
    closes its door</a> to more of the world’s recycling refuse, waste will reach
    crisis levels. Expect the tech sector to pay closer attention to <a href="https://searcherp.techtarget.com/definition/closed-loop-manufacturing-resource-planning-MRP">closed-loop
    manufacturing</a>, where a device is reclaimed and used to build new ones.</p></li></ul>'
  :author: The net of a thousand lies
  :topic_id: 728
- :url: https://onezero.medium.com/apple-is-trying-to-kill-web-technology-a274237c174d?source=search_post---------8
  :title: Apple Is Trying to Kill Web Technology
  :content: '<p>The company has made it extremely difficult to use web-based technology
    on its platforms, and it hopes developers won’t bother</p><p><img src="https://cdn-images-1.medium.com/max/10000/1*zqENj8mfvANOuM2PEcFPxw.jpeg"
    alt="Credit: SOPA Images/Getty Images"><em>Credit: SOPA Images/Getty Images</em></p><p>The
    programming languages used to build the web often find their way into apps, too.
    That’s largely due to software that allows developers to “reuse” the code they
    write for the web in products they build to run on operating systems like Linux,
    Android, Windows, and macOS.</p><p>But Apple has a reason not to like this recycling
    of web technology. It wants its Mac App Store to be filled with apps that you
    can’t find anywhere else, not apps that are available on every platform. <a href="https://9to5mac.com/2019/11/04/electron-app-rejections/">With
    a recent policy change</a>, the company has made it a little more difficult for
    developers to submit apps containing web code.</p><p>The Mac App Store has quietly
    started rejecting apps made with a popular tool called Electron that allows developers
    to base all of their apps on the web-based code. Some of the most popular apps
    in the App Store, like Slack, Spotify, Discord, and WhatsApp, fall into this category.</p><p><a
    href="https://github.com/electron/electron/issues/20027">In a discussion</a> on
    the programming community Github, several developers say rejections for apps that
    they built using Electron — which would were approved in the past — came with
    an explanation that these apps “attempt to hide the use of private APIs,” which
    are APIs built for Apple’s internal usage, rather than for third-party developers.
    Using private APIs to build public-facing apps is commonly frowned upon because
    they may change or break over time, and Apple <a href="https://developer.apple.com/app-store/review/guidelines/#software-requirements">bans</a>
    apps that use them.</p><p>Electron has used these private APIs for years without
    issue. These private APIs allow developers to, for instance, <a href="https://mozillagfx.wordpress.com/2019/10/22/dramatically-reduced-power-usage-in-firefox-70-on-macos-with-core-animation/">drastically
    improve power usage</a> whereas Apple’s sanctioned tools make the user experience
    worse. In the majority of these cases, Apple doesn’t provide real alternatives
    for developers who want to access these private API features.</p><p>Now it’s unlikely
    that the thousands of developers who have built their apps using Electron can
    release updates to them unless the Electron framework releases a major change
    to its implementation.</p><p>Developers could distribute their apps from their
    own websites, asking users to download them directly. But that means abandoning
    features like Apple’s auto-update mechanism from the Mac App Store and iCloud
    sync. And this direct-to-consumer method could soon be locked down, too, with
    Apple’s controversial <a href="https://developer.apple.com/documentation/security/notarizing_your_app_before_distribution">notarization
    requirements</a> potentially requiring their review.</p><p>Apple has a history
    of stunting the web’s progress on its platforms. On iOS, <a href="https://www.howtogeek.com/184283/why-third-party-browsers-will-always-be-inferior-to-safari-on-iphone-and-ipad/">Apple
    doesn’t allow fully independent third-party browsers</a>, requiring all apps to
    leverage its Safari browser when rendering web-based content. While browsers like
    Chrome and Opera are available in the App Store, they must use Apple’s Safari
    browser behind the scenes to render web pages, rather than their own. That means
    Apple has a monopoly on how iPhone and iPad users access the web. To push developers
    toward building native apps on iOS rather than using web technologies, Apple ignores
    popular parts of the <a href="https://www.w3.org/TR/">open web specification</a>
    that other browsers implement, to its own benefit.</p><blockquote><h1>Apple’s
    subtle, anti-competitive practices don’t look terrible in isolation, but together
    they form a clear strategy.</h1></blockquote><p>A technology called WebRTC, for
    example, allows video calling in a web browser without additional software. It
    powers tools like Google Meet. But Apple was incredibly slow to <a href="https://webkit.org/blog/8672/on-the-road-to-webrtc-1-0-including-vp8/">implement
    the specification</a>, leaving out key pieces of functionality, and the technology
    didn’t work <a href="https://bugs.webkit.org/show_bug.cgi?id=183201">when embedded
    inside apps</a>.</p><p>Apple also handicapped an emerging standard called Progressive
    Web Apps (PWAs) — which, like Electron, allows developers to build native-like
    apps for both desktop and mobile — by <a href="https://caniuse.com/#feat=web-app-manifest">partially</a>
    <a href="https://medium.com/@firt/whats-new-on-ios-12-2-for-progressive-web-apps-75c348f8e945">implementing</a>
    it in a way that makes it too inconsistent to rely on. PWA doesn’t have the same
    problem if users open apps in Chrome or Firefox, but iPhone and iPad users can’t
    install third-party browsers, which makes PWA-based technology a non-starter.</p><p>Developers
    use technologies like Electron and PWA because they allow for faster updates across
    platforms without an array of different codebases. Some argue that this results
    in lower quality apps, but I’d argue the alternative is no app at all or apps
    that are rarely updated because maintaining unique Windows, Mac, and web-based
    products is complex and expensive. Apple recently launched a <a href="https://onezero.medium.com/to-revive-the-mac-apple-wants-to-kill-electron-154873336e78">competing
    framework called Catalyst</a>, which allows developers with iPad apps to bring
    them to macOS quickly — a great tool for developers exclusively targeting Apple
    users, but not those building cross-platform apps.</p><p>Apple’s subtle, anti-competitive
    practices don’t look terrible in isolation, but together they form a clear strategy:
    Make it so painful to build with web-based technology on Apple platforms that
    developers won’t bother. Now that the App Store is not accepting apps built using
    Electron, developers will likely find creative ways to work around it, but Apple
    is setting up for a continual cat-and-mouse game as it <a href="https://www.macrumors.com/2019/09/03/apple-macos-catalina-notarization-mac-apps/">plans
    to exert more control</a> over which apps can run on the platform in the future.</p><p>These
    types of changes may be made in the name of privacy or security, but the reality
    is that the argument looks weak when both users and developers simply don’t have
    a choice because Apple controls the platform, browser engine, and the distribution
    method. Regardless of your opinion of Electron app quality, choice is important.</p><p>Apple’s
    control over its app ecosystem is a new type of monopoly that’s hard to understand
    for lawmakers, and difficult for us to fight back against — because there simply
    isn’t a way out of these restrictions when the company controls both the distribution
    method and the platform itself.</p>'
  :author: The net of a thousand lies
  :topic_id: 728
- :url: https://medium.com/art-science/technology-and-the-evolution-of-storytelling-d641d4a27116?source=search_post---------9
  :title: Technology and The Evolution of Storytelling
  :content: '<p>by John Lasseter<em>John Lasseter at the 68th Academy Awards in 1996
    accepting a Special Achievement award for his leadership of Pixar’s “Toy Story”
    team, resulting in the first feature-length computer-animated film.</em></p><p>It
    is such an exciting time to be a filmmaker.</p><p>I do not believe the notion
    that the cinema is dying or dead because it’s amazing what technology can do to
    the cinematic storytelling.</p><p>What’s great about film is it constantly reinvents
    itself. It started as a sheer novelty, those images moving on the screen.</p><p>Then
    it went and every step of the way a new technology started being added — sound,
    color.</p><p>What happens is the film grammar of storytelling evolves and changes
    as well. The technology goes directly with the evolution of the storytelling.</p><p>The
    way films look —it started with old 35mm motion picture cameras, to color with
    the three-strip Technicolor, to cameras that weighed hundreds of pounds and had
    to be on dollies and cranes — that was the film grammar of the day.</p><blockquote><h1>The
    limitations of the technology being used to shoot the films set up what we’ve
    learned as film grammar.</h1></blockquote><p>Then, we came to lighter cameras,
    to handheld cameras, steady cams, and on and on, all the way down to now.</p><p>There’s
    a unique thing to a GoPro.</p><p>There’s a unique thing to an iPhone — the way
    things are shot and the way it’s held. It just gives it a vibrancy you’ve never
    been able to have before.</p><p>I believe new film grammar is going to come from
    these things.</p><p>It evolves, it changes, and it’s in great part because of
    the technology.</p><p><img src="https://cdn-images-1.medium.com/max/4000/1*AnxiGh1JlUSqEqV-OJ0J1Q.jpeg"
    alt="Walt Disney in 1939 receiving one Oscar statuette and seven miniature statuettes
    from Shirley Temple for “Snow White and the Seven Dwarfs”"><em>Walt Disney in
    1939 receiving one Oscar statuette and seven miniature statuettes from Shirley
    Temple for “Snow White and the Seven Dwarfs”</em></p><p>In my own field, in animation,
    a seminal film in the history of animation is <em>Snow White and the Seven Dwarfs</em>,
    Walt Disney’s first feature-length film.</p><p>People thought Walt was insane.</p><p>“People
    aren’t going to sit still for a feature-length cartoon. Are you nuts?”</p><p>But
    Walt was a visionary.</p><p>Walt saw beyond what people were used to. They were
    used to the short cartoon.</p><blockquote><h1>It’s interesting how people cannot
    see beyond what they’re used to.</h1></blockquote><p>There’s a famous statement
    by Henry Ford that before the Model T if you asked people what they wanted, they
    would say, “A faster horse.”</p><p>My own partner at Pixar for 25 years, Steve
    Jobs, never liked market research. Never did market research for anything.</p><p>He
    said, “It’s not the audience’s job to tell us what they want in the future, it’s
    for us to tell them what they want in the future.”</p><blockquote><h1>If you use
    technology correctly, you can change opinions overnight.</h1></blockquote><p>There’s
    a great statement I love. It’s that you only get one chance to make a first impression.</p><p>First
    impressions are nearly impossible to get people off of if they have the wrong
    impression.</p><p>I remember when I first saw computer animation. It wasn’t being
    used for much at the time. It was really geometric, sterile and cold, but I was
    blown away by it. Not by what I was seeing, but the potential I saw in it.</p><p>It
    was true three dimensionality with a control that we had in hand-drawn animation.
    I saw the potential in computer animation and was like, “This is great. Everybody,
    can you see this?”</p><p>But everybody was saying, “It looks like… It’s too sterile.
    No, I don’t like it.”</p><p>I realized they were judging from exactly what they
    were seeing.</p><p>People always push back saying, “It’s too cold, too sterile.”</p><p>In
    the early days of computer graphics, it found its way into special effects.</p><p>There
    were some people who didn’t understand the medium and thought it could do everything.
    There was this company that tried when they were making a movie called <em>Something
    Wicked This Way Comes</em>.</p><p>They had worked on <em>Tron</em>, did some effects,
    and they had a very charismatic effects guy that convinced them they could create
    this magical circus that would erect itself — this evil circus comes to town.</p><p>Disney
    bought in on it and they worked for a very long time. I had a very dear friend
    working on it.</p><p>It was way beyond what the computer could do at that time.
    They ended up cutting the entire sequence out of the film.</p><p>That set back
    computer graphics in the effects world years, because everybody remembered that
    experience.</p><blockquote><h1>It was because people didn’t understand what the
    technology <em>could</em> do.</h1></blockquote><p>About six years after that I
    was working at Lucas Film’s computer division and Dennis Muren, the brilliant
    Dennis Muren, Effects Director at ILM, came over to me and said, “We have this
    effect in a film called <em>Young Sherlock Holmes</em>, and we don’t know how
    to do it. I’m thinking computer graphics.”</p><p>It was only six shots. We said,
    “Let’s try it.”</p><p>It was some of the hardest things we ever did, but I’ll
    never forget when it came out — the effects industry, people from all over the
    world, had no idea how it was done.</p><p>But it worked. It fit in there. It was
    nominated for an Oscar for best visual effects.</p><p>We were so excited. But
    it was focusing on understanding the technology and pushing it to places that
    we couldn’t.</p><blockquote><h1>The goal was to make the technology invisible.</h1></blockquote><p>When
    we became Pixar in 1986 and we started working towards our first feature film,
    I remembered all those projects. I was blessed by, number one, loving the medium
    of computer animation.</p><p>I was just so interested in it and working with the
    people who basically had invented much of computer animation and we were pushing
    it all along.</p><p>We really understood what the computer could and could not
    do.</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*kVJDRemXeuOQlH6DDVYa_w.jpeg"
    alt="Pixar co-founders Ed Catmull, Steve Jobs, and John Lasseter."><em>Pixar co-founders
    Ed Catmull, Steve Jobs, and John Lasseter.</em></p><p>At that time when we rendered
    things, everything kind of looked plastic-y.</p><p>So we started thinking about
    a subject matter that lent itself to the medium at that time.</p><blockquote><h1>“Everything
    looks like plastic, so what if the characters were made of plastic? What if they
    were…toys?”</h1></blockquote><p>That’s one of the reasons why we leaned into toys
    becoming alive as a subject for our very first feature film, <em>Toy Story</em>.</p><p>It
    was about the toys that lent themselves to the medium at that time. We chose toys
    that worked for that.</p><p>In fact, it was better in CG than any other medium
    we could have done because we could make Buzz Lightyear feel like he was made
    of plastic and ball-and-socket joints and we had screws and scratches and decals
    and all this stuff you could not have done in any other medium.</p><p>When it
    came out, our main focus was not the technology.</p><p>What I was scared about
    was that people would be like, “Oh, it’s the first computer-animated feature film.”</p><p>We
    made sure Disney, and all around the world, didn’t sell it as “The First CG film.”</p><p>You
    sell it as a great motion picture, because that’s how we made it.</p><blockquote><h1>We
    focused on the story and hiding the technology.</h1></blockquote><p>It came out
    and people loved it. You watch it today and it’s just as entertaining as the day
    it came out.</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*kiIqKInYaxbllWwnhwJqSQ.jpeg"
    alt="Woody and Buzz in the original “Toy Story”"><em>Woody and Buzz in the original
    “Toy Story”</em></p><p>Like I said, you’ve only got one chance to make a first
    impression.</p><p>Unlike <em>Something Wicked This Way Comes, Toy Story</em> was
    the number one film of the year it came out.</p><p>It was a huge hit and everybody
    started looking at this as a viable filmmaking medium.</p><blockquote><h1>Overnight,
    the opinion changed. Because the technology was used in the right way, telling
    the right story.</h1></blockquote><p>Alfred Hitchcock is one of my favorite filmmakers
    and one of the reasons why I’ve studied and admired his films is that guy used
    new technology in incredible ways, but it was completely invisible in everything
    he made.</p><p>You study his films and realize there’s no way he could have made
    that film, that shot, without that technology.</p><p>But he didn’t want you to
    notice it.</p><p>We focus on entertaining people in new ways, and if you focus
    on the technology too much you get caught up.</p><blockquote><h1>It’s not the
    technology that entertains people, it’s what you do with the technology.</h1></blockquote><p>It’s
    important, I believe, to make the technology invisible, but have it push to do
    something new.</p><p>That’s when you make real breakthroughs.</p><p>If you love
    a technology, if you really, really, really, really love a technology, then dig
    into it.</p><p>Learn as much as you can. It’s fun. That’s what I did with CG.</p><p><img
    src="https://cdn-images-1.medium.com/max/2000/1*_Wl3i7nFJtN4RAXo-YztQA.jpeg" alt="From
    left: Pete Docter, Andrew Stanton, John Lasseter, and Joe Ranft, nominees, Writing
    (Screenplay Written Directly for the Screen) (TOY STORY), at the 1995 (68th) Academy
    Awards Nominees Luncheon."><em>From left: Pete Docter, Andrew Stanton, John Lasseter,
    and Joe Ranft, nominees, Writing (Screenplay Written Directly for the Screen)
    (TOY STORY), at the 1995 (68th) Academy Awards Nominees Luncheon.</em></p><p>I
    was trained by these great Disney artists. I drew. It was all about story, character
    drawing, all that stuff, but when I got into computer graphics I was like, “Oh,
    my god, this is so much fun.”</p><p>I wanted to learn as much as I could.</p><p>The
    more you dig into the technology and the more you learn it, you are going to get
    ideas you would never have thought of without knowing your technology.</p><p>The
    kind of shots you can get from an iPhone that you cannot get with any other camera.
    Use it.</p><p>GoPros: use it. Be inspired by it.</p><p>Try things. It’s digital.
    Get another memory card, for God’s sake.</p><p>You will start creating ideas that
    lend themselves to these things and start looking new.</p><blockquote><h1>When
    you start doing something that’s truly new you will hear, “It’s not going to work.”</h1></blockquote><p>Walt
    Disney heard it. I heard it with CG.</p><p>“ Computer animation is so cold.”</p><p>Really?
    No, I don’t think so.</p><p>You think about it, it’s true for color, sound, feature
    length animation, CG.</p><p>The first feature film shot on an iPhone? “That’s
    not going to work.”</p><p>Yeah, it’s going to work. It’s going to be awesome.</p><p>The
    first feature shot with a GoPro? It’s going to be awesome in the hands of the
    right people.</p><p>The reason why they say this is because it’s not what people
    are used to.</p><p>Before the Model T, you ask people what they want and they’re
    going to want a faster horse. It’s not what they’re used to.</p><p>When I started
    working with CG, I could not wait for the tools to become commonplace.</p><p>In
    the early days, when SIGGRAPH was the only place you could go and see computer
    graphics, it was always fun. Everybody would cheer for reflective clear balls
    floating over a checkerboard and be amazed by it.</p><p>It was in a world where
    all of the art and the CG was being created by the guys who were writing the program.</p><p>There
    was no such thing as off-the-shelf software. There were no tools available.</p><p>They
    were writing their software and then creating it, and they were kind of the artistic
    guys within the computer world.</p><p>They were just showing off the technology.
    I kept thinking to myself, “Yeah, but they’re really ugly. This is like boring.
    Let’s entertain people.”</p><blockquote><h1>I couldn’t wait because I always viewed
    the technology as simply a tool.</h1></blockquote><p>Can you imagine the guy who
    invented the pencil and all of the things that that invention has brought the
    world?</p><p>That’s what I was feeling like with CG.</p><p>I couldn’t wait to
    get it in the hands of everybody to see what they would do.</p><blockquote><h1>The
    mediums we use are simply tools for expressing your art.</h1></blockquote><p>Your
    goal as a filmmaker is to entertain. And to entertain people is about story.</p><p>It’s
    about characters.</p><p>It’s about connecting with that audience.</p><p>It’s making
    that connection where you really deeply entertain an audience.</p><p>But it’s
    not just an art form that we’re in. It’s a business. Entertaining stuff simply
    just does better.</p><blockquote><h1>If you can make people laugh, cry and feel
    things with a film you make, you will be successful.</h1></blockquote><p>No matter
    what medium, any way you’ve distributed it — it all comes down to your knowledge
    skills.</p><p>What makes a good story? How can I tell it properly?</p><p>People
    get so excited about new technologies. I’ve had the question so many times from
    young people, “What software should I use?”</p><blockquote><h1>You know what?
    In your lifetime the software and the technology will change so drastically, it
    doesn’t matter.</h1></blockquote><p>What matters is when you’re young, you get
    excited about learning the fundamentals.</p><p>It sounds so boring to young people
    when they can make a movie so quickly and release it to the world and get millions
    of Likes.</p><p>“It’s so boring. I know how to do that.”</p><p>Trust me, you don’t.</p><p>The
    fundamentals of good storytelling, the fundamentals of film grammar, even though
    it was made with old Mitchell cameras and stuff like that, learn it.</p><p>Learn
    the fundamentals of animation. Learn the fundamentals of physics and things like
    that, of basic color, basic design.</p><p>This is the foundation of the building
    of your career.</p><p>Then, as you get into new technology, you’ll know exactly
    what to do.</p><blockquote><h1>And your work will not be about the technology.
    It will be about connecting and entertaining people.</h1></blockquote><p>No matter
    the length of your film — 30 seconds, five minutes, 22 minutes, feature length
    — it needs a story. It needs a beginning, a middle and an end.</p><p>It needs
    to deeply connect with people.</p><p>There are big differences between storytelling
    at 30 seconds or a feature film. Big differences.</p><p><img src="https://cdn-images-1.medium.com/max/2560/1*50BOA2AeBYI4JOHwbZpfWw.jpeg"
    alt=""></p><p>We did a series of short films in the beginning of Pixar and we
    did television commercials.</p><p>We were thinking the next step for us was to
    do a Christmas special, but Disney threw us in the deep end, and we developed
    a feature film.</p><p>It was amazing what we didn’t know.</p><p>But I went back
    to my traditional training I had learned from my mentors — Frank Thomas, Ollie
    Johnston, and the great Disney animators that were still working at the studio
    when I started there — and the fundamentals of animation they kept talking about.</p><p>Ollie
    Johnston would turn to me and I was expecting something about arcs and lines and
    silhouette value and all that stuff.</p><p>He would turn and say, “John, what’s
    the character thinking?”</p><p>It was amazing to me, just that simple statement.
    It was not about the drawing.</p><blockquote><h1>It was never about the drawing
    to them. It was about that character and what it’s thinking.</h1></blockquote><p>Through
    pure movement they taught me to bring a character to life and give it an emotion,
    a personality, a uniqueness, and it was done through just pure motion.</p><p>So
    when I started working with a computer, I just brought that technology with me.
    As we started developing the story, it was always about emotion. It was always
    about emotion from day one with <em>Toy Story</em>.</p><p>It was about emotion,
    making you feel.</p><p>I’ve admired Walt Disney so much my whole life and part
    of it is because he entertained people like no other person in history has ever
    done. The way he makes you feel when you watch his movies, the way he makes you
    feel when go through that tunnel under the train station at Disneyland and you’re
    transported.</p><p>It’s about emotion and that connection.</p><blockquote><h1>Walt
    always said, “For every laugh, there should be a tear.”</h1></blockquote><p>It
    felt like that core emotion. That became the hallmark of what we tried to do at
    Pixar — to do it with the new technology.</p><p>I think the biggest thing for
    us is we studied films. We watched films religiously.</p><p>With <em>Toy Story,</em>
    it was a buddy picture. We watched every buddy picture we could find and analyzed
    it. Good ones, and it’s very important to watch bad ones too.</p><p>You start
    understanding what they did. Don’t copy things. It’s about understanding and learning.</p><p>Very,
    very, very important: Do not work in a vacuum.</p><p>You have to surround yourself
    with trusted people. You get so immersed in your work, you will not be able to
    see the forest from the trees. Frankly, you’ll be studying the pine needles and
    worrying about them.</p><p>You need someone to help you back up and take a look
    at the forest and see where things are working or not working.</p><p>And you need
    to surround yourself with people whose judgment you trust and they can be brutally
    honest with you.</p><p>As an artist, showing unfinished work to people is really
    difficult. It’s really hard. It always is hard. It always will be hard. It never
    gets any easier, but you have to do it.</p><blockquote><h1>Andrew Stanton, my
    creative partner at Pixar, has this fantastic phrase that I use all the time,
    “Be wrong as fast as you can.”</h1></blockquote><p>Trust me, when you go from
    an outline to a treatment, your first treatment sucks and you do revisions and
    talk to people and you get something working really great.</p><p>Go to your first
    draft of the script, it sucks. You do it a whole bunch of times.</p><p>For us,
    we go to story reels, the first story reel sucks. But the longer you say, “I’m
    not ready yet, give me a little more time, give me a little more time,” and like
    that, it’s not going to help the problem.</p><p>You’re just going to be polishing.
    You’re not going to see where it’s not working.</p><p>Get it up there. Throw it
    up there as fast as you can, talk about it, tear it back down, put it back up
    there. Keep doing this.</p><p>Surround yourself with people you trust.</p><p>Be
    thirsty for knowledge.</p><p>It will always make your work better. The market
    is changing really, really quickly.</p><p>Who knows what the business will look
    like ten years from now?</p><p>I know one thing for sure.</p><blockquote><h1>If
    you create characters people connect with and tell stories that deeply entertain
    and move them, the audience will come.</h1><p><center><em>This is an excerpt from
    *</em>John Lasseter*<em>’s presentation at “<a href="http://www.oscars.org/events/new-audience-moviegoing-connected-world">The
    New Audience: Moviegoing In A Connected World</a>,” an Academy event held on May
    12, 2015.</em></center></p></blockquote>'
  :author: ART & SCIENCE
  :topic_id: 728
